{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ESFJ', 'ESFJ', 'ESFJ', 'ESFJ']\n",
      "['ESTJ', 'ESTJ', 'ESTJ', 'ESTJ']\n",
      "['ISFJ', 'ISFJ', 'ISFJ', 'ISFJ']\n",
      "['ISTJ', 'ISTJ', 'ISTJ', 'ISTJ']\n",
      "['ENFP', 'ENFP', 'ENFP', 'ENFP']\n",
      "['ENFJ', 'ENFJ', 'ENFJ', 'ENFJ']\n",
      "['INFP', 'INFP', 'INFP', 'INFP']\n",
      "['INFJ', 'INFJ', 'INFJ', 'INFJ']\n",
      "['ENTP', 'ENTP', 'ENTP', 'ENTP']\n",
      "['ENTJ', 'ENTJ', 'ENTJ', 'ENTJ']\n",
      "['INTP', 'INTP', 'INTP', 'INTP']\n",
      "['INTJ', 'INTJ', 'INTJ', 'INTJ']\n",
      "['ESFP', 'ESFP', 'ESFP', 'ESFP']\n",
      "['ESTP', 'ESTP', 'ESTP', 'ESTP']\n",
      "['ISFP', 'ISFP', 'ISFP', 'ISFP']\n",
      "['ISTP', 'ISTP', 'ISTP', 'ISTP']\n"
     ]
    }
   ],
   "source": [
    "homogenous = pd.read_csv(\"Conditions/Homogenous.csv\")\n",
    "fiftyfifty = pd.read_csv(\"Conditions/FiftyFifty.csv\")\n",
    "heterogenous = pd.read_csv(\"Conditions/Heterogenous.csv\")\n",
    "\n",
    "\n",
    "for i in (range(len(homogenous.index))):\n",
    "    print(list(homogenous.iloc[i][1:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ExScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.SeScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ThScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.JuScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                Ind_Solution_lst.append(random.randint(range_elements[0], range_elements[1]))\n",
    "                Ind_Solution_attr_lst.append(random.randint(range_elements[0], range_elements[1]))\n",
    "        \n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"ESTJ\"\n",
    "B = \"ISTJ\"\n",
    "agent_type_equality(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.809663  0.550679  0.351181  0.307924  0.577451\n",
      "1    Bravo  ESFJ  0.695214  0.726146  0.240172  0.776741  0.645478\n",
      "2  Charlie  INTP  0.192562  0.411793  0.782302  0.243381  0.558861\n",
      "3    Delta  INTP  0.079059  0.315904  0.938174  0.010562  0.490654\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(10, [1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 37, 40, 45, 90, 87, 76, 90, 27, 31]"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[76, 15, 40, 45, 77, 87, 76, 90, 27, 31],\n",
       " [76, 41, 16, 45, 83, 87, 76, 42, 27, 31],\n",
       " [76, 37, 40, 45, 90, 67, 76, 51, 27, 31],\n",
       " [76, 84, 7, 11, 90, 87, 47, 90, 27, 31]]"
      ]
     },
     "execution_count": 1204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [76, 99, 48, 45, 27, 87, 76, 90, 27, 31]\n",
      "Bravo [76, 6, 10, 45, 62, 87, 76, 48, 27, 31]\n",
      "Charlie [76, 37, 40, 45, 90, 71, 76, 56, 27, 31]\n",
      "Delta [76, 28, 62, 14, 90, 87, 64, 90, 27, 31]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 0.7\n",
      "Bravo 0.6\n",
      "Charlie 0.8\n",
      "Delta 0.6\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([76, 6, 10, 45, 62, 87, 76, 48, 27, 31], 19, True)\n",
      "[[76, 15, 40, 45, 77, 87, 76, 90, 27, 31], [76, 41, 16, 45, 83, 87, 76, 42, 27, 31], [76, 37, 40, 45, 90, 67, 76, 51, 27, 31], [76, 84, 7, 11, 90, 87, 47, 90, 27, 31]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1201-23e3f51f328b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m homogenous_ind_df, homogeous_group_df = abm_model(condition = homogenous, \n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mmax_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mn_part_exercises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrange_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mn_simulations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1200-e68cc4fc8640>\u001b[0m in \u001b[0;36mabm_model\u001b[0;34m(condition, max_ticks, n_part_exercises, range_solution, n_simulations)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m## Getting data frames for the group and individual levels ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mexercise_run_dict_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexercise_run_list_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexercise_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_part_exercises\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_solution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_simulations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#creating dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mexercise_run_group_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise_run_dict_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#creating dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1199-c1116413510f>\u001b[0m in \u001b[0;36mexercise_run\u001b[0;34m(student_list, max_ticks, n_part_exercises, range_solution, n_simulations)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m## generating group solution ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mgroup_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollaborative_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudygroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ticks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mn_tick_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_solution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# appending the number of ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mconsensus_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_solution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# appending whether a consensus was reached or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1182-0fa0924786b4>\u001b[0m in \u001b[0;36mcollaborative_solution\u001b[0;34m(studygroup, max_ticks)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProposed_Solution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# looping through all part-exercises and evaluating against proposed solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mcoin_toss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompromising\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresenter_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcademic_Skill\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcoin_toss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInd_Solution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProposed_Solution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "homogenous_ind_df, homogeous_group_df = abm_model(condition = homogenous, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>studygroup</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_adaptation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>[INTJ, INTJ, INTJ, INTJ]</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.097422</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>[INTJ, INTJ, INTJ, INTJ]</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.097468</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>[ENTJ, ENTJ, ENTJ, ENTJ]</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>[INTJ, INTJ, INTJ, INTJ]</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.101445</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>[INFJ, INFJ, INFJ, INFJ]</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>[ISTP, ISTP, ISTP, ISTP]</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.149519</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>[ISFP, ISFP, ISFP, ISFP]</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.133417</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>[ISFP, ISFP, ISFP, ISFP]</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.144554</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>[ISTP, ISTP, ISTP, ISTP]</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.144914</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>[ESFP, ESFP, ESFP, ESFP]</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.130885</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                studygroup  avg_accuracy  std_accuracy  avg_adaptation\n",
       "47  INTJ  [INTJ, INTJ, INTJ, INTJ]         0.897      0.097422           0.178\n",
       "44  INTJ  [INTJ, INTJ, INTJ, INTJ]         0.890      0.097468           0.179\n",
       "38  ENTJ  [ENTJ, ENTJ, ENTJ, ENTJ]         0.885      0.112583           0.181\n",
       "46  INTJ  [INTJ, INTJ, INTJ, INTJ]         0.903      0.101445           0.189\n",
       "28  INFJ  [INFJ, INFJ, INFJ, INFJ]         0.888      0.101272           0.190\n",
       "..   ...                       ...           ...           ...             ...\n",
       "61  ISTP  [ISTP, ISTP, ISTP, ISTP]         0.738      0.149519           0.387\n",
       "58  ISFP  [ISFP, ISFP, ISFP, ISFP]         0.740      0.133417           0.390\n",
       "56  ISFP  [ISFP, ISFP, ISFP, ISFP]         0.748      0.144554           0.394\n",
       "60  ISTP  [ISTP, ISTP, ISTP, ISTP]         0.760      0.144914           0.396\n",
       "49  ESFP  [ESFP, ESFP, ESFP, ESFP]         0.737      0.130885           0.399\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_homogenous = homogeous_group_df.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_homogenous\n",
    "\n",
    "homogenous_ind_df.sort_values(\"avg_adaptation\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_ind, fifty_group = abm_model(condition = fiftyfifty, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>studygroup</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_adaptation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>[ENTJ, ENTJ, ISTJ, ISTJ]</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.107009</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>[ENFJ, ENFJ, INFP, INFP]</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.110472</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>[ENFJ, ENFJ, ISTP, ISTP]</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.104805</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>[ENFJ, ENFJ, ISTP, ISTP]</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>[ENTJ, ENTJ, ISTJ, ISTJ]</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.095917</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ESTP, ESTP, ISFJ, ISFJ]</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ESTP, ESTP, ISFJ, ISFJ]</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.166045</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>[ESFJ, ESFJ, ISTP, ISTP]</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.145822</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>[ESTJ, ESTJ, ISFP, ISFP]</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.125698</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>[ESTJ, ESTJ, ISFP, ISFP]</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.166886</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                studygroup  avg_accuracy  std_accuracy  avg_adaptation\n",
       "61  ENTJ  [ENTJ, ENTJ, ISTJ, ISTJ]         0.893      0.107009           0.194\n",
       "45  ENFJ  [ENFJ, ENFJ, INFP, INFP]         0.886      0.110472           0.198\n",
       "13  ENFJ  [ENFJ, ENFJ, ISTP, ISTP]         0.896      0.104805           0.199\n",
       "12  ENFJ  [ENFJ, ENFJ, ISTP, ISTP]         0.885      0.108051           0.204\n",
       "60  ENTJ  [ENTJ, ENTJ, ISTJ, ISTJ]         0.880      0.095917           0.207\n",
       "..   ...                       ...           ...           ...             ...\n",
       "57  ESTP  [ESTP, ESTP, ISFJ, ISFJ]         0.760      0.135647           0.360\n",
       "56  ESTP  [ESTP, ESTP, ISFJ, ISFJ]         0.727      0.166045           0.363\n",
       "35  ISTP  [ESFJ, ESFJ, ISTP, ISTP]         0.744      0.145822           0.371\n",
       "51  ISFP  [ESTJ, ESTJ, ISFP, ISFP]         0.760      0.125698           0.375\n",
       "50  ISFP  [ESTJ, ESTJ, ISFP, ISFP]         0.743      0.166886           0.385\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 1171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_fifty = fifty_group.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_fifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_ind, hetero_group = abm_model(condition = heterogenous, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>18.14</td>\n",
       "      <td>7.782056</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>0.116102</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.132102</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.117320</td>\n",
       "      <td>17.70</td>\n",
       "      <td>7.555792</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>-0.00025</td>\n",
       "      <td>0.112833</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.132193</td>\n",
       "      <td>19.45</td>\n",
       "      <td>7.001964</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>-0.00450</td>\n",
       "      <td>0.121623</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.121589</td>\n",
       "      <td>17.86</td>\n",
       "      <td>7.477994</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.255147</td>\n",
       "      <td>0.01750</td>\n",
       "      <td>0.111999</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>0.127980</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.117047</td>\n",
       "      <td>13.96</td>\n",
       "      <td>6.580152</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>0.01525</td>\n",
       "      <td>0.104337</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.123693</td>\n",
       "      <td>15.63</td>\n",
       "      <td>7.036555</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.00875</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.108310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>17.20</td>\n",
       "      <td>8.168231</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>-0.00075</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.120183</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.126491</td>\n",
       "      <td>18.56</td>\n",
       "      <td>7.373357</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.120688</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.137055</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.125395</td>\n",
       "      <td>17.79</td>\n",
       "      <td>7.424682</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.00475</td>\n",
       "      <td>0.129648</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.142334</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.123353</td>\n",
       "      <td>16.29</td>\n",
       "      <td>7.250234</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.255147</td>\n",
       "      <td>0.01850</td>\n",
       "      <td>0.117931</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.131909</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.122715</td>\n",
       "      <td>14.21</td>\n",
       "      <td>6.659272</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>-0.01400</td>\n",
       "      <td>0.112823</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.119746</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.110901</td>\n",
       "      <td>13.45</td>\n",
       "      <td>7.030469</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>-0.00125</td>\n",
       "      <td>0.099522</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.108646</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.107238</td>\n",
       "      <td>14.49</td>\n",
       "      <td>7.458545</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.097340</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.113574</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.109631</td>\n",
       "      <td>13.63</td>\n",
       "      <td>6.524807</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>0.01075</td>\n",
       "      <td>0.093759</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.100817</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.109266</td>\n",
       "      <td>13.05</td>\n",
       "      <td>7.132146</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>0.01225</td>\n",
       "      <td>0.099968</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>0.097872</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.102269</td>\n",
       "      <td>11.26</td>\n",
       "      <td>6.683741</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.099499</td>\n",
       "      <td>-0.00150</td>\n",
       "      <td>0.088729</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "9   ESTJ  ISFP    ISTJ  ESFP         0.768      0.130292       18.14   \n",
       "5   ESTJ  ESTP    ISTP  INTJ         0.794      0.117320       17.70   \n",
       "2   ISTJ  ISTP    ESFP  ENTJ         0.795      0.132193       19.45   \n",
       "13  ENTP  INTP    ESFP  ISFP         0.804      0.121589       17.86   \n",
       "6   ENFP  ISFP    ESFP  INFP         0.810      0.117047       13.96   \n",
       "12  ESFJ  ISFJ    ENFP  INFP         0.810      0.123693       15.63   \n",
       "1   ISFJ  ESTP    ISFP  ENFJ         0.811      0.131069       17.20   \n",
       "8   ESFJ  ISTP    ESTP  ENTP         0.820      0.126491       18.56   \n",
       "4   ESFJ  ISFJ    ISTJ  INTP         0.826      0.125395       17.79   \n",
       "15  ENTJ  INTJ    ESTP  ISTP         0.828      0.123353       16.29   \n",
       "0   ESFJ  ESTJ    ENFP  INFJ         0.829      0.122715       14.21   \n",
       "11  ENFJ  INTP    INFJ  ENTP         0.849      0.110901       13.45   \n",
       "3   INTP  INTJ    INFP  ENTP         0.850      0.107238       14.49   \n",
       "14  ESTJ  ISTJ    ENFJ  INFJ         0.859      0.109631       13.63   \n",
       "10  ENFP  INTJ    INFP  ENTJ         0.869      0.109266       13.05   \n",
       "7   INFJ  ENFJ    ENTJ  ISFJ         0.871      0.102269       11.26   \n",
       "\n",
       "    std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "9     7.782056           0.86       0.346987          -0.01125   \n",
       "5     7.555792           0.89       0.312890          -0.00025   \n",
       "2     7.001964           0.89       0.312890          -0.00450   \n",
       "13    7.477994           0.93       0.255147           0.01750   \n",
       "6     6.580152           0.95       0.217945           0.01525   \n",
       "12    7.036555           0.98       0.140000           0.00875   \n",
       "1     8.168231           0.85       0.357071          -0.00075   \n",
       "8     7.373357           0.91       0.286182           0.02675   \n",
       "4     7.424682           0.90       0.300000          -0.00475   \n",
       "15    7.250234           0.93       0.255147           0.01850   \n",
       "0     6.659272           0.95       0.217945          -0.01400   \n",
       "11    7.030469           0.97       0.170587          -0.00125   \n",
       "3     7.458545           0.94       0.237487           0.01500   \n",
       "14    6.524807           0.97       0.170587           0.01075   \n",
       "10    7.132146           0.97       0.170587           0.01225   \n",
       "7     6.683741           0.99       0.099499          -0.00150   \n",
       "\n",
       "    std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "9           0.116102              -0.143            0.132102               6  \n",
       "5           0.112833              -0.141            0.128915               5  \n",
       "2           0.121623              -0.139            0.127197               6  \n",
       "13          0.111999              -0.111            0.127980               6  \n",
       "6           0.104337              -0.112            0.124322               4  \n",
       "12          0.101512              -0.113            0.108310               6  \n",
       "1           0.117975              -0.134            0.120183               6  \n",
       "8           0.120688              -0.096            0.137055               4  \n",
       "4           0.129648              -0.121            0.142334               5  \n",
       "15          0.117931              -0.120            0.131909               6  \n",
       "0           0.112823              -0.131            0.119746               5  \n",
       "11          0.099522              -0.114            0.108646               6  \n",
       "3           0.097340              -0.099            0.113574               3  \n",
       "14          0.093759              -0.094            0.100817               6  \n",
       "10          0.099968              -0.089            0.097872               6  \n",
       "7           0.088729              -0.099            0.094335               4  "
      ]
     },
     "execution_count": 1168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_hetero = hetero_group.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_hetero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8166250000000002, 0.8207500000000001, 0.8245625000000002)\n",
      "(0.046472942396624764, 0.029085004727522457, 0.028122430438175194)\n",
      "(11.745624999999999, 17.392500000000002, 15.791875)\n",
      "(2.8001137672200036, 2.301272745677921, 2.325035534002652)\n"
     ]
    }
   ],
   "source": [
    "homogenous_mean_acc = np.mean(homogeous_group_df['avg_accuracy'])\n",
    "fifty_mean_acc = np.mean(fifty_group['avg_accuracy'])\n",
    "hetero_mean_acc = np.mean(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_std_acc = np.std(homogeous_group_df['avg_accuracy'])\n",
    "fifty_std_acc = np.std(fifty_group['avg_accuracy'])\n",
    "hetero_std_acc = np.std(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_mean_tick = np.mean(homogeous_group_df['avg_n_tick'])\n",
    "fifty_mean_tick = np.mean(fifty_group['avg_n_tick'])\n",
    "hetero_mean_tick = np.mean(hetero_group['avg_n_tick'])\n",
    "\n",
    "homogenous_std_tick = np.std(homogeous_group_df['avg_n_tick'])\n",
    "fifty_std_tick = np.std(fifty_group['avg_n_tick'])\n",
    "hetero_std_tick = np.std(hetero_group['avg_n_tick'])\n",
    "\n",
    "print(tuple([homogenous_mean_acc, fifty_mean_acc, hetero_mean_acc]))\n",
    "print(tuple([homogenous_std_acc, fifty_std_acc, hetero_std_acc]))\n",
    "\n",
    "print(tuple([homogenous_mean_tick, fifty_mean_tick, hetero_mean_tick]))\n",
    "print(tuple([homogenous_std_tick, fifty_std_tick, hetero_std_tick]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
