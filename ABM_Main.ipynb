{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = pd.read_csv(\"pt_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = random.choice(max_vals)\n",
    "    else:\n",
    "        student.ExScore = random.choice(min_vals)\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = random.choice(max_vals)\n",
    "    else:\n",
    "        student.SeScore = random.choice(min_vals)\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = random.choice(max_vals)\n",
    "    else:\n",
    "        student.ThScore = random.choice(min_vals)\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = random.choice(max_vals)\n",
    "    else:\n",
    "        student.JuScore = random.choice(min_vals)\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                wrong_answer = random.randint(range_elements[0], range_elements[1])\n",
    "                Ind_Solution_lst.append(wrong_answer)\n",
    "                Ind_Solution_attr_lst.append(wrong_answer)\n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2]\n",
      "[1, 3, 2]\n",
      "[1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "A = [1, 3, 2]\n",
    "B = [1, 3, 2]\n",
    "C = [1, 3, 3]\n",
    "\n",
    "for i in range(3):\n",
    "    if A[i] == B[i]:\n",
    "        C[i] = A[i]\n",
    "    if A[i] == C[i]:\n",
    "        B[i] = A[i]\n",
    "    if B[i] == C[i]:\n",
    "        A[i] = B[i]\n",
    "\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(C) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    for i in range(8): # loop that agrees on a solution if three of the members have the same solution before we start talking.\n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[2][i]): # delta is odd one out\n",
    "                individual_solutions[3][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[3][i]): # charlie is odd one out\n",
    "                individual_solutions[2][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[2][i] == individual_solutions[3][i]): # bravo is odd one out\n",
    "                individual_solutions[1][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[1][i] == individual_solutions[2][i] == individual_solutions[3][i]): # alfa is odd one out\n",
    "                individual_solutions[0][i] = individual_solutions[1][i]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "student_list_test = [\"ESFP\", \"ISFP\", \"ISFP\", \"ISFP\"]\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.509321  0.555311  0.349937  0.406134  0.471538\n",
      "1    Bravo  ISFP  0.265921  0.653190  0.371819  0.480933  0.517853\n",
      "2  Charlie  ISFP  0.328291  0.575488  0.320783  0.140129  0.449663\n",
      "3    Delta  ISFP  0.385768  0.590190  0.300422  0.158048  0.438224\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(8, [1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1, 4, 6, 7, 4, 3, 6]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1, 3, 6, 7, 2, 5, 6],\n",
       " [5, 1, 4, 6, 7, 4, 3, 6],\n",
       " [5, 7, 4, 6, 7, 4, 3, 6],\n",
       " [5, 1, 4, 6, 7, 4, 3, 6]]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [5, 1, 3, 6, 7, 2, 5, 6]\n",
      "Bravo [5, 1, 4, 6, 7, 4, 3, 6]\n",
      "Charlie [5, 7, 4, 6, 7, 4, 3, 6]\n",
      "Delta [5, 1, 4, 6, 7, 4, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 0.625\n",
      "Bravo 1.0\n",
      "Charlie 0.875\n",
      "Delta 1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([5, 1, 4, 6, 7, 4, 3, 6], 1, True)\n",
      "[[5, 1, 3, 6, 7, 2, 5, 6], [5, 1, 4, 6, 7, 4, 3, 6], [5, 7, 4, 6, 7, 4, 3, 6], [5, 1, 4, 6, 7, 4, 3, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ind, all_group = abm_model(condition = all_groups, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 8, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 10\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>13.6</td>\n",
       "      <td>8.151074</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.134375</td>\n",
       "      <td>0.079119</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>16.3</td>\n",
       "      <td>6.116371</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.340347</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.101934</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.858753</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.071329</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.560958</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>15.2</td>\n",
       "      <td>6.161169</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.103692</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>16.1</td>\n",
       "      <td>5.281098</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>0.110087</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>11.7</td>\n",
       "      <td>8.660831</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.074280</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.282512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.239539</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>16.1</td>\n",
       "      <td>5.281098</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.105002</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9.162969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>17.2</td>\n",
       "      <td>4.512206</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.118955</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>12.6</td>\n",
       "      <td>8.321058</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.086659</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7.244998</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.088609</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.059777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.093958</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.606815</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.058044</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.939741</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.072349</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.042727</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.453858</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>13.1</td>\n",
       "      <td>7.515983</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.101213</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7.977468</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.128087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6.726069</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.073221</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.139194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>13.7</td>\n",
       "      <td>6.293648</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>0.095248</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.623224</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.280097</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.089759</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>14.3</td>\n",
       "      <td>6.148984</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.624953</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.155485</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.080283</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.733046</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7.749194</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.512206</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.101550</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.368175</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.169558</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.881860</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.114436</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.602906</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.069597</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.130919</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.075584</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>13.5</td>\n",
       "      <td>7.200694</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.059293</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.116881</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.100244</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.362065</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>11.1</td>\n",
       "      <td>7.751774</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.153125</td>\n",
       "      <td>0.073221</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>14.9</td>\n",
       "      <td>7.133723</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.048814</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.173127</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.717798</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.696490</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.095607</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>14.6</td>\n",
       "      <td>5.885576</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.100972</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.165831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.135960</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.328507</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.025667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.119610</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.224957</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>11.9</td>\n",
       "      <td>8.251666</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>0.087332</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "1970  ISFJ  ENTP    ISFP  ISTP        0.8625      0.087500        13.6   \n",
       "1124  ESTJ  ISTJ    ESFP  ISFP        0.8625      0.087500        16.3   \n",
       "1092  ESTJ  ISTJ    INFJ  ESFP        0.8875      0.067315        14.0   \n",
       "2027  ISFJ  INTJ    ESFP  ESTP        0.8500      0.108972        12.8   \n",
       "2314  ISTJ  INFP    ENTP  ESFP        0.9375      0.062500        12.1   \n",
       "1451  ESTJ  INTP    ESFP  ESFP        0.8625      0.103833        15.2   \n",
       "2505  ISTJ  ESTP    ISFP  ISTP        0.8250      0.114564        16.1   \n",
       "1616  ISFJ  ISTJ    ENFP  INFP        0.8625      0.117925        11.7   \n",
       "580   ESFJ  ENFJ    INTP  ISTP        0.8875      0.103833        13.0   \n",
       "2827  ENFP  INTP    INTJ  ESTP        0.9125      0.080039        12.1   \n",
       "2829  ENFP  INTP    INTJ  ISTP        0.8875      0.103833        16.1   \n",
       "2080  ISTJ  ISTJ    ENFP  ISTP        0.9250      0.082916        12.2   \n",
       "3159  ENFJ  ISFP    ISTP  ISTP        0.9000      0.108972        17.2   \n",
       "1897  ISFJ  INFJ    INFJ  ESTP        0.8875      0.130504        12.6   \n",
       "1835  ISFJ  ENFJ    ISTP  ISTP        0.9125      0.097628        15.1   \n",
       "414   ESFJ  ISTJ    INFJ  ISFP        0.9250      0.100000        10.8   \n",
       "3290  INFP  ENTP    ESFP  ISTP        0.8375      0.080039        13.5   \n",
       "3288  INFP  ENTP    ESFP  ESTP        0.9000      0.108972        14.8   \n",
       "1410  ESTJ  ENTP    ISFP  ISTP        0.9125      0.057282        13.0   \n",
       "889   ESTJ  ESTJ    INFP  ISFP        0.9250      0.061237        12.2   \n",
       "3116  ENFJ  INTP    ESFP  ESFP        0.9000      0.108972        13.1   \n",
       "3048  ENFJ  ENTP    ENTP  ISTP        0.8750      0.111803        12.6   \n",
       "2047  ISFJ  ESTP    ESTP  ISFP        0.8500      0.108972        12.6   \n",
       "1453  ESTJ  INTP    ESFP  ISFP        0.8375      0.148429        13.7   \n",
       "2387  ISTJ  INFJ    ESTP  ISTP        0.9250      0.082916        12.2   \n",
       "2382  ISTJ  INFJ    ESFP  ESTP        0.9250      0.082916        10.2   \n",
       "1653  ISFJ  ISTJ    INFJ  ESTP        0.8500      0.108972        14.3   \n",
       "2341  ISTJ  INFP    ESTP  ISFP        0.8875      0.103833        14.1   \n",
       "1470  ESTJ  INTJ    ESTP  ESTP        0.8625      0.130504        14.1   \n",
       "902   ESTJ  ESTJ    ENTP  INTP        0.8875      0.130504        12.0   \n",
       "529   ESFJ  ENFP    ISTP  ISTP        0.8625      0.103833        11.5   \n",
       "1459  ESTJ  INTP    ISFP  ISTP        0.8000      0.114564        15.2   \n",
       "512   ESFJ  ENFP    INTP  ESTP        0.8875      0.087500        13.9   \n",
       "2417  ISTJ  ENTP    ESFP  ESFP        0.8000      0.169558        14.8   \n",
       "1374  ESTJ  INFJ    ISFP  ISTP        0.8750      0.111803        11.3   \n",
       "3158  ENFJ  ISFP    ISFP  ISTP        0.9000      0.108972        12.5   \n",
       "2852  ENFP  INTJ    ISFP  ISFP        0.9375      0.062500        13.5   \n",
       "1861  ISFJ  INFP    ENTP  ISFP        0.9000      0.108972        12.5   \n",
       "1826  ISFJ  ENFJ    ESFP  ESFP        0.8625      0.103833        12.0   \n",
       "1181  ESTJ  ENFP    ENTP  ISTP        0.9625      0.057282        11.1   \n",
       "3748  ENTJ  ISFP    ISTP  ISTP        0.9000      0.108972        14.9   \n",
       "205   ESFJ  ESTJ    INFP  INTP        0.9125      0.080039        12.0   \n",
       "1903  ISFJ  INFJ    ENTP  INTJ        0.9000      0.093541        10.0   \n",
       "3379  INFP  ISFP    ISTP  ISTP        0.8875      0.103833        15.5   \n",
       "3874  ISFP  ISTP    ISTP  ISTP        0.8375      0.137500        14.6   \n",
       "1947  ISFJ  ENTP    ENTJ  ESFP        0.8500      0.093541        14.5   \n",
       "3794  INTP  ESFP    ISFP  ISTP        0.8625      0.117925        13.5   \n",
       "2823  ENFP  INTP    INTP  ISFP        0.8500      0.122474        12.8   \n",
       "2504  ISTJ  ESTP    ISFP  ISFP        0.8125      0.115244        12.0   \n",
       "345   ESFJ  ISFJ    INTP  ISTP        0.9000      0.108972        11.9   \n",
       "\n",
       "      std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "1970    8.151074            0.4       0.489898          0.134375   \n",
       "1124    6.116371            0.4       0.489898          0.093750   \n",
       "1092    6.340347            0.5       0.500000          0.075000   \n",
       "2027    7.858753            0.5       0.500000          0.071875   \n",
       "2314    8.560958            0.5       0.500000          0.121875   \n",
       "1451    6.161169            0.5       0.500000          0.103125   \n",
       "2505    5.281098            0.5       0.500000          0.084375   \n",
       "1616    8.660831            0.5       0.500000          0.046875   \n",
       "580     8.282512            0.5       0.500000          0.103125   \n",
       "2827    8.239539            0.5       0.500000          0.106250   \n",
       "2829    5.281098            0.5       0.500000          0.121875   \n",
       "2080    9.162969            0.5       0.500000          0.118750   \n",
       "3159    4.512206            0.5       0.500000          0.121875   \n",
       "1897    8.321058            0.5       0.500000          0.059375   \n",
       "1835    7.244998            0.5       0.500000          0.106250   \n",
       "414     8.059777            0.6       0.489898          0.143750   \n",
       "3290    6.606815            0.6       0.489898          0.078125   \n",
       "3288    6.939741            0.6       0.489898          0.100000   \n",
       "1410    7.042727            0.6       0.489898          0.131250   \n",
       "889     7.453858            0.6       0.489898          0.118750   \n",
       "3116    7.515983            0.6       0.489898          0.096875   \n",
       "3048    7.977468            0.6       0.489898          0.112500   \n",
       "2047    6.726069            0.6       0.489898          0.096875   \n",
       "1453    6.293648            0.6       0.489898          0.090625   \n",
       "2387    8.623224            0.6       0.489898          0.118750   \n",
       "2382    8.280097            0.6       0.489898          0.109375   \n",
       "1653    6.148984            0.6       0.489898          0.050000   \n",
       "2341    6.624953            0.6       0.489898          0.112500   \n",
       "1470    6.155485            0.6       0.489898          0.062500   \n",
       "902     7.733046            0.6       0.489898          0.125000   \n",
       "529     7.749194            0.6       0.489898          0.096875   \n",
       "1459    4.512206            0.6       0.489898          0.025000   \n",
       "512     7.368175            0.6       0.489898          0.100000   \n",
       "2417    6.881860            0.6       0.489898          0.040625   \n",
       "1374    8.602906            0.6       0.489898          0.068750   \n",
       "3158    7.130919            0.6       0.489898          0.140625   \n",
       "2852    7.200694            0.6       0.489898          0.125000   \n",
       "1861    7.116881            0.6       0.489898          0.121875   \n",
       "1826    7.362065            0.6       0.489898          0.078125   \n",
       "1181    7.751774            0.6       0.489898          0.153125   \n",
       "3748    7.133723            0.6       0.489898          0.137500   \n",
       "205     8.173127            0.6       0.489898          0.103125   \n",
       "1903    8.717798            0.6       0.489898          0.056250   \n",
       "3379    5.696490            0.6       0.489898          0.131250   \n",
       "3874    5.885576            0.6       0.489898          0.112500   \n",
       "1947    6.135960            0.6       0.489898          0.062500   \n",
       "3794    6.328507            0.6       0.489898          0.131250   \n",
       "2823    7.025667            0.6       0.489898          0.078125   \n",
       "2504    7.224957            0.6       0.489898          0.062500   \n",
       "345     8.251666            0.6       0.489898          0.084375   \n",
       "\n",
       "      std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "1970          0.079119             -0.0250            0.075000               5  \n",
       "1124          0.076547             -0.0500            0.082916               6  \n",
       "1092          0.101934             -0.0500            0.114564               6  \n",
       "2027          0.071329             -0.0500            0.114564               7  \n",
       "2314          0.053125              0.0000            0.055902               7  \n",
       "1451          0.103692             -0.0625            0.100778               5  \n",
       "2505          0.110087             -0.0750            0.114564               3  \n",
       "1616          0.074280             -0.0625            0.083853               6  \n",
       "580           0.096875             -0.0500            0.114564               8  \n",
       "2827          0.067315             -0.0125            0.103833               5  \n",
       "2829          0.105002             -0.0625            0.100778               4  \n",
       "2080          0.065252             -0.0250            0.093541               5  \n",
       "3159          0.118955             -0.0250            0.108972               5  \n",
       "1897          0.086659             -0.0625            0.115244               5  \n",
       "1835          0.088609             -0.0375            0.080039               6  \n",
       "414           0.093958             -0.0250            0.075000               4  \n",
       "3290          0.058044             -0.0375            0.080039               6  \n",
       "3288          0.072349             -0.0250            0.093541               5  \n",
       "1410          0.060596             -0.0125            0.087500               5  \n",
       "889           0.043750             -0.0500            0.061237               7  \n",
       "3116          0.101213             -0.0250            0.108972               5  \n",
       "3048          0.089704             -0.0625            0.128087               4  \n",
       "2047          0.073221             -0.0750            0.139194               5  \n",
       "1453          0.095248             -0.0750            0.100000               6  \n",
       "2387          0.051916             -0.0250            0.075000               5  \n",
       "2382          0.089759             -0.0125            0.103833               7  \n",
       "1653          0.089704             -0.0750            0.114564               5  \n",
       "2341          0.090786             -0.0375            0.080039               5  \n",
       "1470          0.080283             -0.0875            0.125623               4  \n",
       "902           0.083853             -0.0375            0.080039               5  \n",
       "529           0.084375             -0.0625            0.100778               6  \n",
       "1459          0.101550             -0.1250            0.111803               4  \n",
       "512           0.076291              0.0000            0.079057               6  \n",
       "2417          0.114436             -0.1250            0.136931               5  \n",
       "1374          0.069597             -0.0375            0.112500               6  \n",
       "3158          0.075584             -0.0375            0.097628               4  \n",
       "2852          0.059293             -0.0125            0.087500               5  \n",
       "1861          0.100244             -0.0375            0.097628               5  \n",
       "1826          0.046875             -0.0625            0.083853               4  \n",
       "1181          0.073221              0.0250            0.050000               5  \n",
       "3748          0.048814              0.0000            0.079057               4  \n",
       "205           0.075325             -0.0500            0.100000               8  \n",
       "1903          0.093541             -0.0750            0.100000               5  \n",
       "3379          0.095607              0.0125            0.087500               3  \n",
       "3874          0.100972             -0.0250            0.165831               1  \n",
       "1947          0.069877             -0.0750            0.100000               7  \n",
       "3794          0.110750             -0.0375            0.080039               4  \n",
       "2823          0.119610             -0.0875            0.125623               4  \n",
       "2504          0.086150             -0.1125            0.103833               4  \n",
       "345           0.087332             -0.0375            0.097628               6  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_group_sorted = all_group.sort_values(\"avg_consensus\", ascending = True)\n",
    "all_group_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group.to_csv('10sim_NEW_all_group_3.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
