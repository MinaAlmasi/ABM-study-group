{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = pd.read_csv(\"pt_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ExScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.SeScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ThScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.JuScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                if i == 0 or i == 1:\n",
    "                    if student.Type[0] == \"E\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[0] == \"I\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 2 or i == 3:\n",
    "                    if student.Type[1] == \"N\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[1] == \"S\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 4 or i == 5:\n",
    "                    if student.Type[2] == \"T\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[2] == \"F\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 6 or i == 7:\n",
    "                    if student.Type[3] == \"J\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[3] == \"P\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "        \n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2]\n",
      "[1, 3, 2]\n",
      "[1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "A = [1, 3, 2]\n",
    "B = [1, 3, 2]\n",
    "C = [1, 3, 3]\n",
    "\n",
    "for i in range(3):\n",
    "    if A[i] == B[i]:\n",
    "        C[i] = A[i]\n",
    "    if A[i] == C[i]:\n",
    "        B[i] = A[i]\n",
    "    if B[i] == C[i]:\n",
    "        A[i] = B[i]\n",
    "\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(C) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    for i in range(8): # loop that agrees on a solution if three of the members have the same solution before we start talking.\n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[2][i]): # delta is odd one out\n",
    "                individual_solutions[3][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[3][i]): # charlie is odd one out\n",
    "                individual_solutions[2][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[2][i] == individual_solutions[3][i]): # bravo is odd one out\n",
    "                individual_solutions[1][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[1][i] == individual_solutions[2][i] == individual_solutions[3][i]): # alfa is odd one out\n",
    "                individual_solutions[0][i] = individual_solutions[1][i]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "student_list_test = [\"ESFP\", \"ISFP\", \"ISFP\", \"ISFP\"]\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.804347  0.669793  0.144982  0.326544  0.426160\n",
      "1    Bravo  ISFP  0.351843  0.926226  0.254038  0.116269  0.356804\n",
      "2  Charlie  ISFP  0.291185  0.630172  0.246807  0.288598  0.529854\n",
      "3    Delta  ISFP  0.019719  0.728605  0.355660  0.306970  0.432681\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(8, [1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 3, 8, 6, 3, 8, 7]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 5, 3, 8, 6, 4, 3, 7],\n",
       " [4, 4, 3, 8, 4, 3, 8, 7],\n",
       " [5, 4, 3, 8, 6, 3, 8, 7],\n",
       " [5, 5, 3, 8, 6, 3, 8, 7]]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [5, 5, 3, 8, 6, 4, 3, 7]\n",
      "Bravo [4, 4, 3, 8, 4, 3, 8, 7]\n",
      "Charlie [5, 4, 3, 8, 6, 3, 8, 7]\n",
      "Delta [5, 5, 3, 8, 6, 3, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 0.75\n",
      "Bravo 0.625\n",
      "Charlie 0.875\n",
      "Delta 1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([5, 5, 3, 8, 6, 3, 8, 7], 9, True)\n",
      "[[5, 5, 3, 8, 6, 4, 3, 7], [4, 4, 3, 8, 4, 3, 8, 7], [5, 4, 3, 8, 6, 3, 8, 7], [5, 5, 3, 8, 6, 3, 8, 7]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ind, all_group = abm_model(condition = all_groups, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 8, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 10\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2.647640</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5.243091</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.128125</td>\n",
       "      <td>0.098276</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.696490</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.125351</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.160078</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>15.9</td>\n",
       "      <td>4.392038</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.020956</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>15.4</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>15.2</td>\n",
       "      <td>5.455273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.075842</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.128087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>15.1</td>\n",
       "      <td>5.957348</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.076801</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7.203471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.072686</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.604346</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.088167</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>14.9</td>\n",
       "      <td>4.504442</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.074017</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>14.9</td>\n",
       "      <td>4.887740</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>14.8</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.029925</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.101934</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>14.8</td>\n",
       "      <td>4.975942</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.844706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>14.5</td>\n",
       "      <td>5.084290</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.088444</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.387482</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>14.3</td>\n",
       "      <td>4.879549</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.057707</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>14.3</td>\n",
       "      <td>4.337050</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>0.109196</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>14.3</td>\n",
       "      <td>7.029225</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.083619</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>14.3</td>\n",
       "      <td>4.960847</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.110087</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.165831</td>\n",
       "      <td>14.3</td>\n",
       "      <td>6.000833</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.129791</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>0.141973</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.1</td>\n",
       "      <td>4.948737</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.128125</td>\n",
       "      <td>0.071875</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.049113</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.100778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>14.1</td>\n",
       "      <td>5.068530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.135641</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.292853</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.087779</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.882176</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.073686</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.196773</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.134375</td>\n",
       "      <td>0.076610</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.197222</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>0.074543</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.286288</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>13.9</td>\n",
       "      <td>6.204031</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.150520</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>13.9</td>\n",
       "      <td>6.920260</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.105697</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.618011</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.106617</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.139754</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.077429</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.077560</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>13.9</td>\n",
       "      <td>6.655073</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.340981</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.169558</td>\n",
       "      <td>13.9</td>\n",
       "      <td>6.171710</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.102174</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.166589</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.100049</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.453858</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.161169</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.060596</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.305553</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.075519</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.867314</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.088444</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>13.8</td>\n",
       "      <td>6.823489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.084085</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>13.7</td>\n",
       "      <td>7.184010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.064726</td>\n",
       "      <td>-0.0750</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.796874</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>13.7</td>\n",
       "      <td>7.470609</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>0.083911</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>13.7</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.059293</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.128087</td>\n",
       "      <td>13.7</td>\n",
       "      <td>5.916925</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "3791  INTP  ESFP    ESTP  ISFP        0.8000      0.114564        17.7   \n",
       "1658  ISFJ  ISTJ    ENTP  INTP        0.8750      0.125000        16.9   \n",
       "3794  INTP  ESFP    ISFP  ISTP        0.8375      0.137500        16.5   \n",
       "3746  ENTJ  ISFP    ISFP  ISFP        0.9000      0.075000        15.9   \n",
       "3856  ESFP  ESTP    ISTP  ISTP        0.8250      0.127475        15.7   \n",
       "2050  ISFJ  ESTP    ISFP  ISTP        0.9000      0.075000        15.4   \n",
       "2470  ISTJ  INTP    ESTP  ESTP        0.8375      0.112500        15.2   \n",
       "3521  INFJ  INTJ    ESTP  ISFP        0.8625      0.067315        15.1   \n",
       "2385  ISTJ  INFJ    ESTP  ESTP        0.8750      0.096825        15.1   \n",
       "2158  ISTJ  ENFP    ENFP  ISTP        0.8625      0.117925        15.0   \n",
       "1831  ISFJ  ENFJ    ESTP  ISFP        0.8000      0.082916        14.9   \n",
       "2754  ENFP  INFJ    ISTP  ISTP        0.8500      0.134629        14.9   \n",
       "3621  ENTP  INTP    ESFP  ESFP        0.9000      0.050000        14.8   \n",
       "1493  ESTJ  ISFP    ISFP  ISTP        0.8625      0.117925        14.8   \n",
       "2588  ENFP  ENFP    ISTP  ISTP        0.8500      0.075000        14.8   \n",
       "1310  ESTJ  INFP    INTP  INTP        0.8625      0.117925        14.5   \n",
       "1274  ESTJ  ENFJ    ISFP  ISTP        0.8875      0.103833        14.5   \n",
       "2073  ISTJ  ISTJ    ENFP  ENTP        0.8750      0.136931        14.5   \n",
       "2869  ENFP  ESTP    ISFP  ISTP        0.8250      0.082916        14.3   \n",
       "3212  INFP  INFP    ESTP  ISTP        0.8625      0.087500        14.3   \n",
       "3779  INTP  INTJ    ESFP  ISTP        0.9000      0.050000        14.3   \n",
       "3362  INFP  ESFP    ESFP  ESTP        0.8250      0.114564        14.3   \n",
       "2504  ISTJ  ESTP    ISFP  ISFP        0.7250      0.165831        14.3   \n",
       "3747  ENTJ  ISFP    ISFP  ISTP        0.8750      0.000000        14.1   \n",
       "3733  ENTJ  ESFP    ESFP  ISTP        0.8750      0.079057        14.1   \n",
       "2222  ISTJ  ENFP    ISFP  ISFP        0.8500      0.145774        14.1   \n",
       "3535  INFJ  ESFP    ISTP  ISTP        0.9375      0.083853        14.0   \n",
       "640   ESFJ  INFP    INTJ  ISTP        0.8750      0.096825        14.0   \n",
       "3663  ENTP  ISFP    ISFP  ISTP        0.9125      0.097628        14.0   \n",
       "3152  ENFJ  ESTP    ESTP  ISFP        0.9125      0.080039        14.0   \n",
       "1081  ESTJ  ISTJ    INFP  INTP        0.8750      0.079057        14.0   \n",
       "1452  ESTJ  INTP    ESFP  ESTP        0.9250      0.082916        13.9   \n",
       "1188  ESTJ  ENFP    ENTJ  ISTP        0.8625      0.103833        13.9   \n",
       "1451  ESTJ  INTP    ESFP  ESFP        0.8750      0.125000        13.9   \n",
       "3739  ENTJ  ESFP    ISTP  ISTP        0.8750      0.111803        13.9   \n",
       "444   ESFJ  ISTJ    ESFP  ISFP        0.8875      0.117925        13.9   \n",
       "773   ESFJ  INTP    ESFP  ISFP        0.9125      0.097628        13.9   \n",
       "1315  ESTJ  INFP    INTP  ISTP        0.8875      0.152582        13.9   \n",
       "529   ESFJ  ENFP    ISTP  ISTP        0.8250      0.169558        13.9   \n",
       "1276  ESTJ  INFP    INFP  INFP        0.9125      0.112500        13.8   \n",
       "3811  INTJ  INTJ    ESFP  ESFP        0.8750      0.096825        13.8   \n",
       "1873  ISFJ  INFP    INTP  ESTP        0.9375      0.062500        13.8   \n",
       "3528  INFJ  ESFP    ESFP  ISFP        0.8625      0.067315        13.8   \n",
       "2094  ISTJ  ISTJ    INFP  ENTP        0.8375      0.125623        13.8   \n",
       "779   ESFJ  INTP    ISFP  ISTP        0.9125      0.057282        13.8   \n",
       "1885  ISFJ  INFP    ESTP  ESTP        0.8375      0.097628        13.7   \n",
       "1968  ISFJ  ENTP    ESTP  ISTP        0.8625      0.130504        13.7   \n",
       "1453  ESTJ  INTP    ESFP  ISFP        0.9125      0.097628        13.7   \n",
       "1054  ESTJ  ISTJ    ENFP  ENFP        0.8375      0.097628        13.7   \n",
       "357   ESFJ  ISFJ    ESTP  ISTP        0.8125      0.128087        13.7   \n",
       "\n",
       "      std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "3791    2.647640            0.6       0.489898          0.028125   \n",
       "1658    5.243091            0.6       0.489898          0.128125   \n",
       "3794    5.696490            0.5       0.500000          0.096875   \n",
       "3746    4.392038            0.7       0.458258          0.156250   \n",
       "3856    5.020956            0.7       0.458258          0.096875   \n",
       "2050    6.200000            0.6       0.489898          0.150000   \n",
       "2470    5.455273            0.7       0.458258          0.065625   \n",
       "3521    5.957348            0.8       0.400000          0.081250   \n",
       "2385    7.203471            0.5       0.500000          0.053125   \n",
       "2158    4.604346            0.6       0.489898          0.087500   \n",
       "1831    4.504442            0.6       0.489898          0.040625   \n",
       "2754    4.887740            0.7       0.458258          0.078125   \n",
       "3621    5.600000            0.7       0.458258          0.125000   \n",
       "1493    6.029925            0.7       0.458258          0.081250   \n",
       "2588    4.975942            0.7       0.458258          0.081250   \n",
       "1310    6.844706            0.6       0.489898          0.096875   \n",
       "1274    5.084290            0.8       0.400000          0.103125   \n",
       "2073    4.387482            0.7       0.458258          0.087500   \n",
       "2869    4.879549            0.8       0.400000          0.053125   \n",
       "3212    4.337050            0.7       0.458258          0.115625   \n",
       "3779    7.029225            0.7       0.458258          0.087500   \n",
       "3362    4.960847            0.7       0.458258          0.071875   \n",
       "2504    6.000833            0.8       0.400000          0.046875   \n",
       "3747    4.948737            0.7       0.458258          0.128125   \n",
       "3733    7.049113            0.5       0.500000          0.075000   \n",
       "2222    5.068530            1.0       0.000000          0.112500   \n",
       "3535    6.292853            0.7       0.458258          0.143750   \n",
       "640     6.000000            0.7       0.458258          0.065625   \n",
       "3663    5.882176            0.7       0.458258          0.118750   \n",
       "3152    6.196773            0.7       0.458258          0.134375   \n",
       "1081    7.197222            0.5       0.500000          0.090625   \n",
       "1452    7.286288            0.5       0.500000          0.112500   \n",
       "1188    6.204031            0.9       0.300000          0.075000   \n",
       "1451    6.920260            0.7       0.458258          0.106250   \n",
       "3739    3.618011            0.8       0.400000          0.106250   \n",
       "444     7.077429            0.7       0.458258          0.087500   \n",
       "773     6.655073            0.6       0.489898          0.143750   \n",
       "1315    7.340981            0.7       0.458258          0.118750   \n",
       "529     6.171710            0.7       0.458258          0.096875   \n",
       "1276    7.166589            0.8       0.400000          0.109375   \n",
       "3811    7.453858            0.5       0.500000          0.062500   \n",
       "1873    6.161169            0.7       0.458258          0.150000   \n",
       "3528    6.305553            0.8       0.400000          0.081250   \n",
       "2094    6.867314            0.8       0.400000          0.040625   \n",
       "779     6.823489            1.0       0.000000          0.106250   \n",
       "1885    7.184010            0.6       0.489898          0.065625   \n",
       "1968    4.796874            0.7       0.458258          0.075000   \n",
       "1453    7.470609            0.7       0.458258          0.115625   \n",
       "1054    5.900000            0.6       0.489898          0.062500   \n",
       "357     5.916925            0.7       0.458258          0.065625   \n",
       "\n",
       "      std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "3791          0.084375             -0.1000            0.122474               5  \n",
       "1658          0.098276             -0.0250            0.134629               6  \n",
       "3794          0.125351             -0.0500            0.160078               4  \n",
       "3746          0.064043              0.0375            0.080039               4  \n",
       "3856          0.104068             -0.0500            0.114564               3  \n",
       "2050          0.104396             -0.0125            0.103833               4  \n",
       "2470          0.075842             -0.0625            0.128087               4  \n",
       "3521          0.076801             -0.0625            0.083853               7  \n",
       "2385          0.072686             -0.0875            0.112500               6  \n",
       "2158          0.088167             -0.0750            0.082916               7  \n",
       "1831          0.074017             -0.1125            0.103833               6  \n",
       "2754          0.100049             -0.1125            0.152582               6  \n",
       "3621          0.076547             -0.0125            0.087500               5  \n",
       "1493          0.101934             -0.0750            0.127475               4  \n",
       "2588          0.056250             -0.0625            0.062500               6  \n",
       "1310          0.071875             -0.0625            0.115244               4  \n",
       "1274          0.088444             -0.0500            0.082916               7  \n",
       "2073          0.103456             -0.0625            0.083853               7  \n",
       "2869          0.057707             -0.1000            0.075000               5  \n",
       "3212          0.109196             -0.0125            0.087500               5  \n",
       "3779          0.083619             -0.0750            0.061237               5  \n",
       "3362          0.110087             -0.1250            0.096825               3  \n",
       "2504          0.129791             -0.1375            0.141973               4  \n",
       "3747          0.071875             -0.0750            0.082916               5  \n",
       "3733          0.067315             -0.0625            0.100778               5  \n",
       "2222          0.135641             -0.0250            0.108972               4  \n",
       "3535          0.052663             -0.0250            0.075000               5  \n",
       "640           0.087779             -0.0625            0.083853               7  \n",
       "3663          0.073686             -0.0375            0.080039               4  \n",
       "3152          0.076610              0.0000            0.079057               5  \n",
       "1081          0.074543             -0.0500            0.082916               6  \n",
       "1452          0.090786              0.0000            0.079057               4  \n",
       "1188          0.074215             -0.0625            0.150520               6  \n",
       "1451          0.105697             -0.0250            0.122474               5  \n",
       "3739          0.106617             -0.0625            0.139754               5  \n",
       "444           0.077560             -0.0375            0.112500               5  \n",
       "773           0.061237              0.0125            0.067315               5  \n",
       "1315          0.098623             -0.0375            0.137500               5  \n",
       "529           0.102174             -0.0875            0.148429               6  \n",
       "1276          0.100049             -0.0250            0.134629               4  \n",
       "3811          0.096825             -0.1000            0.122474               8  \n",
       "1873          0.060596             -0.0125            0.067315               6  \n",
       "3528          0.075519             -0.1000            0.093541               4  \n",
       "2094          0.088444             -0.1000            0.108972               6  \n",
       "779           0.084085             -0.0250            0.108972               5  \n",
       "1885          0.064726             -0.0750            0.082916               6  \n",
       "1968          0.114564             -0.0875            0.097628               5  \n",
       "1453          0.083911              0.0000            0.136931               6  \n",
       "1054          0.059293             -0.0875            0.080039               7  \n",
       "357           0.078375             -0.1125            0.117925               6  "
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_group_sorted = all_group.sort_values(\"avg_n_tick\", ascending = False)\n",
    "all_group_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group.to_csv('10sim_NEW_all_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81921875, 0.819453125, 0.8228125000000001)\n",
      "(0.049299536873458547, 0.02613056441189848, 0.02945965196247233)\n",
      "(10.00125, 14.089999999999998, 12.9225)\n",
      "(2.1900681353556104, 1.7158161323405257, 1.4767595437307994)\n"
     ]
    }
   ],
   "source": [
    "homogenous_mean_acc = np.mean(homogeous_group_df['avg_accuracy'])\n",
    "fifty_mean_acc = np.mean(fifty_group['avg_accuracy'])\n",
    "hetero_mean_acc = np.mean(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_std_acc = np.std(homogeous_group_df['avg_accuracy'])\n",
    "fifty_std_acc = np.std(fifty_group['avg_accuracy'])\n",
    "hetero_std_acc = np.std(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_mean_tick = np.mean(homogeous_group_df['avg_n_tick'])\n",
    "fifty_mean_tick = np.mean(fifty_group['avg_n_tick'])\n",
    "hetero_mean_tick = np.mean(hetero_group['avg_n_tick'])\n",
    "\n",
    "homogenous_std_tick = np.std(homogeous_group_df['avg_n_tick'])\n",
    "fifty_std_tick = np.std(fifty_group['avg_n_tick'])\n",
    "hetero_std_tick = np.std(hetero_group['avg_n_tick'])\n",
    "\n",
    "print(tuple([homogenous_mean_acc, fifty_mean_acc, hetero_mean_acc]))\n",
    "print(tuple([homogenous_std_acc, fifty_std_acc, hetero_std_acc]))\n",
    "\n",
    "print(tuple([homogenous_mean_tick, fifty_mean_tick, hetero_mean_tick]))\n",
    "print(tuple([homogenous_std_tick, fifty_std_tick, hetero_std_tick]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
