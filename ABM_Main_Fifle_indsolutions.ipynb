{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = pd.read_csv(\"pt_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ExScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.SeScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ThScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.JuScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                if i == 0 or i == 1:\n",
    "                    if student.Type[0] == \"E\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[0] == \"I\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 2 or i == 3:\n",
    "                    if student.Type[1] == \"N\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[1] == \"S\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 4 or i == 5:\n",
    "                    if student.Type[2] == \"T\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[2] == \"F\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 6 or i == 7:\n",
    "                    if student.Type[3] == \"J\":\n",
    "                        wrong_answer = random.randint(1, 2)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[3] == \"P\":\n",
    "                        wrong_answer = random.randint(3, 4)\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "        \n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 2]\n",
      "[1, 3, 2]\n",
      "[1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "A = [1, 3, 2]\n",
    "B = [1, 3, 2]\n",
    "C = [1, 3, 3]\n",
    "\n",
    "for i in range(3):\n",
    "    if A[i] == B[i]:\n",
    "        C[i] = A[i]\n",
    "    if A[i] == C[i]:\n",
    "        B[i] = A[i]\n",
    "    if B[i] == C[i]:\n",
    "        A[i] = B[i]\n",
    "\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(C) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    for i in range(8): # loop that agrees on a solution if three of the members have the same solution before we start talking.\n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[2][i]): # delta is odd one out\n",
    "                individual_solutions[3][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[1][i] == individual_solutions[3][i]): # charlie is odd one out\n",
    "                individual_solutions[2][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[0][i] == individual_solutions[2][i] == individual_solutions[3][i]): # bravo is odd one out\n",
    "                individual_solutions[1][i] = individual_solutions[0][i]\n",
    "            \n",
    "            if (individual_solutions[1][i] == individual_solutions[2][i] == individual_solutions[3][i]): # alfa is odd one out\n",
    "                individual_solutions[0][i] = individual_solutions[1][i]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "student_list_test = [\"ESFP\", \"ISFP\", \"ISFP\", \"ISFP\"]\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.641834  0.527124  0.089206  0.296635  0.507603\n",
      "1    Bravo  ISFP  0.471925  0.568932  0.126592  0.304839  0.507440\n",
      "2  Charlie  ISFP  0.162991  0.935293  0.279521  0.470497  0.374200\n",
      "3    Delta  ISFP  0.183615  0.825838  0.148106  0.201814  0.422566\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(8, [1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 3, 3, 2, 3, 1, 5]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 8, 3, 3, 2, 3, 1, 5],\n",
       " [1, 8, 4, 3, 4, 3, 1, 5],\n",
       " [4, 8, 3, 3, 2, 3, 1, 5],\n",
       " [1, 8, 3, 3, 2, 3, 1, 5]]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [1, 8, 3, 3, 2, 3, 1, 5]\n",
      "Bravo [1, 8, 4, 3, 4, 3, 1, 5]\n",
      "Charlie [4, 8, 3, 3, 2, 3, 1, 5]\n",
      "Delta [1, 8, 3, 3, 2, 3, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 1.0\n",
      "Bravo 0.75\n",
      "Charlie 0.875\n",
      "Delta 1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 8, 3, 3, 2, 3, 1, 5], 1, True)\n",
      "[[1, 8, 3, 3, 2, 3, 1, 5], [1, 8, 4, 3, 4, 3, 1, 5], [4, 8, 3, 3, 2, 3, 1, 5], [1, 8, 3, 3, 2, 3, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ind, all_group = abm_model(condition = all_groups, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 8, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 10\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.536244</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.407402</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.082443</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181250</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.749815</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.178125</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.311894</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.518435</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.064348</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.130217</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.738694</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.222188</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.392038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.079119</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.759202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.817216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.060998</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.732864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.072686</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.063003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.024118</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.087332</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.906776</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.062578</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.708949</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.069597</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.239475</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.088167</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.168468</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.068530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.045928</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.296575</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.377214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.294518</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.058962</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.517246</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.070986</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.456779</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.082443</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.497333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.063003</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.088018</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.100244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.916925</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.060029</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.082372</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.953150</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.069104</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.073896</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.107756</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.457211</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.070503</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.406247</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.070503</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.365460</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.085525</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.655133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>11.4</td>\n",
       "      <td>7.512656</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.591661</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.091055</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.664762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.604463</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.868560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.079474</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.731492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.124605</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.091643</td>\n",
       "      <td>-0.0250</td>\n",
       "      <td>0.156125</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.337192</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.499091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.081490</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.814637</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.050389</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.172866</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>13.2</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "2098  ISTJ  ISTJ    INFP  ESFP        0.9875      0.037500         6.5   \n",
       "3852  ESFP  ESTP    ESTP  ISFP        0.9375      0.083853         7.4   \n",
       "2774  ENFP  ENTP    INTP  ISFP        0.9750      0.050000         5.7   \n",
       "1325  ESTJ  INFP    ESTP  ESTP        0.9375      0.083853         9.2   \n",
       "1229  ESTJ  ENFJ    INFP  ISFP        0.9750      0.075000         6.6   \n",
       "3826  INTJ  ESFP    ESTP  ISFP        0.9250      0.082916        10.1   \n",
       "2196  ISTJ  ENFP    ENTP  ISTP        0.9625      0.080039         9.4   \n",
       "3099  ENFJ  ENTJ    ESTP  ESTP        0.9500      0.082916         9.3   \n",
       "774   ESFJ  INTP    ESFP  ISTP        0.9375      0.062500         9.8   \n",
       "3575  ENTP  ENTP    ESFP  ISTP        0.9250      0.082916        10.1   \n",
       "2390  ISTJ  INFJ    ISTP  ISTP        0.9750      0.050000         6.5   \n",
       "1375  ESTJ  INFJ    ISTP  ISTP        0.9500      0.061237         7.6   \n",
       "2587  ENFP  ENFP    ISFP  ISTP        0.9250      0.082916        10.0   \n",
       "2482  ISTJ  INTJ    ESFP  ESTP        0.9750      0.050000         6.2   \n",
       "3766  INTP  INTP    ESTP  ISFP        0.9125      0.097628        11.1   \n",
       "3767  INTP  INTP    ESTP  ISTP        0.9125      0.112500         7.9   \n",
       "2496  ISTJ  ESFP    ESTP  ISFP        0.9375      0.115244         8.7   \n",
       "3770  INTP  INTP    ISTP  ISTP        0.9500      0.082916         7.3   \n",
       "1103  ESTJ  ISTJ    ENTP  ISTP        0.9250      0.082916         8.5   \n",
       "19    ESFJ  ESFJ    ESTJ  ENFP        0.9250      0.061237         6.9   \n",
       "1032  ESTJ  ISFJ    ESFP  ESTP        0.9500      0.061237         8.4   \n",
       "2044  ISFJ  ESFP    ISFP  ISTP        0.9500      0.061237         9.2   \n",
       "3209  INFP  INFP    ESFP  ISTP        0.9625      0.057282        10.7   \n",
       "1962  ISFJ  ENTP    ESFP  ESFP        0.9500      0.061237         6.4   \n",
       "1100  ESTJ  ISTJ    ENTP  ESFP        0.9625      0.057282         9.9   \n",
       "660   ESFJ  INFJ    ENTP  ENTP        0.9625      0.057282         8.3   \n",
       "2560  ENFP  ENFP    ENTP  ISTP        0.9375      0.062500         8.2   \n",
       "2018  ISFJ  INTP    ISFP  ISFP        0.9250      0.082916        13.6   \n",
       "3309  INFP  ENTJ    INTP  ISTP        0.9625      0.057282         6.3   \n",
       "3148  ENFJ  ESFP    ISFP  ISFP        0.9250      0.100000        11.8   \n",
       "2743  ENFP  INFJ    INTJ  ISFP        0.9625      0.080039         7.6   \n",
       "2024  ISFJ  INTJ    INTJ  ISFP        0.9750      0.050000         7.4   \n",
       "1860  ISFJ  INFP    ENTP  ESTP        0.9750      0.050000         7.3   \n",
       "1813  ISFJ  ENFJ    ENTJ  ISFP        0.9625      0.057282         8.4   \n",
       "1662  ISFJ  ISTJ    ENTP  ISFP        0.9375      0.083853        10.5   \n",
       "1635  ISFJ  ISTJ    ENFJ  ISFP        0.9875      0.037500         4.8   \n",
       "2855  ENFP  ESFP    ESFP  ESFP        0.9125      0.097628        11.4   \n",
       "2498  ISTJ  ESFP    ISFP  ISFP        0.9375      0.115244         7.5   \n",
       "932   ESTJ  ESTJ    ESTP  ISTP        0.9500      0.082916         6.2   \n",
       "1971  ISFJ  ENTP    ISTP  ISTP        0.9750      0.050000         4.7   \n",
       "3699  ENTJ  INTP    INTP  ISTP        0.9750      0.050000         7.4   \n",
       "1095  ESTJ  ISTJ    INFJ  ISTP        0.9750      0.050000         8.2   \n",
       "133   ESFJ  ESFJ    ISFP  ISFP        0.9500      0.061237         6.5   \n",
       "3608  ENTP  ENTJ    ISFP  ISTP        0.9625      0.057282         8.2   \n",
       "3855  ESFP  ESTP    ISFP  ISTP        0.8625      0.117925        11.2   \n",
       "918   ESTJ  ESTJ    INTP  ESTP        0.9500      0.082916        10.2   \n",
       "2835  ENFP  INTP    ESTP  ISFP        0.9125      0.080039         9.6   \n",
       "1549  ISFJ  ISFJ    INFP  ENTJ        0.9875      0.037500         4.3   \n",
       "165   ESFJ  ESTJ    ISTJ  ISTJ        0.9500      0.082916         8.5   \n",
       "2195  ISTJ  ENFP    ENTP  ISFP        0.9125      0.097628        13.2   \n",
       "\n",
       "      std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "2098    5.536244            0.9       0.300000          0.184375   \n",
       "3852    5.407402            0.9       0.300000          0.181250   \n",
       "2774    4.100000            1.0       0.000000          0.181250   \n",
       "1325    6.749815            0.9       0.300000          0.178125   \n",
       "1229    6.311894            0.9       0.300000          0.175000   \n",
       "3826    6.518435            0.8       0.400000          0.175000   \n",
       "2196    7.130217            0.8       0.400000          0.175000   \n",
       "3099    6.738694            0.9       0.300000          0.171875   \n",
       "774     7.222188            0.8       0.400000          0.168750   \n",
       "3575    4.392038            1.0       0.000000          0.165625   \n",
       "2390    4.759202            1.0       0.000000          0.165625   \n",
       "1375    5.817216            1.0       0.000000          0.165625   \n",
       "2587    4.732864            1.0       0.000000          0.165625   \n",
       "2482    6.063003            1.0       0.000000          0.165625   \n",
       "3766    6.024118            0.9       0.300000          0.165625   \n",
       "3767    5.906776            0.9       0.300000          0.165625   \n",
       "2496    6.708949            0.9       0.300000          0.162500   \n",
       "3770    7.239475            0.9       0.300000          0.162500   \n",
       "1103    6.168468            0.9       0.300000          0.162500   \n",
       "19      5.068530            1.0       0.000000          0.162500   \n",
       "1032    7.296575            0.9       0.300000          0.162500   \n",
       "2044    4.377214            1.0       0.000000          0.162500   \n",
       "3209    7.294518            0.7       0.458258          0.162500   \n",
       "1962    5.517246            0.9       0.300000          0.162500   \n",
       "1100    6.456779            0.9       0.300000          0.162500   \n",
       "660     7.497333            0.8       0.400000          0.162500   \n",
       "2560    6.063003            0.9       0.300000          0.159375   \n",
       "2018    7.088018            0.6       0.489898          0.159375   \n",
       "3309    5.916925            0.9       0.300000          0.159375   \n",
       "3148    7.082372            0.8       0.400000          0.159375   \n",
       "2743    5.953150            0.9       0.300000          0.159375   \n",
       "2024    7.073896            0.9       0.300000          0.159375   \n",
       "1860    7.457211            0.8       0.400000          0.159375   \n",
       "1813    6.406247            0.9       0.300000          0.159375   \n",
       "1662    7.365460            0.8       0.400000          0.159375   \n",
       "1635    3.655133            1.0       0.000000          0.159375   \n",
       "2855    7.512656            0.7       0.458258          0.159375   \n",
       "2498    6.591661            0.8       0.400000          0.159375   \n",
       "932     4.664762            1.0       0.000000          0.159375   \n",
       "1971    5.604463            0.9       0.300000          0.159375   \n",
       "3699    5.868560            1.0       0.000000          0.159375   \n",
       "1095    6.079474            0.9       0.300000          0.156250   \n",
       "133     5.731492            1.0       0.000000          0.156250   \n",
       "3608    7.124605            0.9       0.300000          0.156250   \n",
       "3855    3.400000            1.0       0.000000          0.156250   \n",
       "918     6.337192            0.9       0.300000          0.156250   \n",
       "2835    5.499091            1.0       0.000000          0.156250   \n",
       "1549    5.814637            0.9       0.300000          0.156250   \n",
       "165     7.172866            0.8       0.400000          0.156250   \n",
       "2195    5.600000            0.7       0.458258          0.156250   \n",
       "\n",
       "      std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "2098          0.080828              0.0750            0.082916               6  \n",
       "3852          0.082443              0.0375            0.097628               3  \n",
       "2774          0.051916              0.0375            0.057282               5  \n",
       "1325          0.067097             -0.0250            0.093541               4  \n",
       "1229          0.090786              0.0250            0.075000               7  \n",
       "3826          0.064348             -0.0125            0.117925               6  \n",
       "2196          0.068750              0.0500            0.061237               6  \n",
       "3099          0.052756              0.0125            0.087500               5  \n",
       "774           0.068750              0.0000            0.079057               6  \n",
       "3575          0.079119             -0.0125            0.117925               4  \n",
       "2390          0.039652              0.0125            0.037500               4  \n",
       "1375          0.060998              0.0250            0.050000               5  \n",
       "2587          0.072686              0.0000            0.079057               5  \n",
       "2482          0.067097              0.0250            0.075000               6  \n",
       "3766          0.087332             -0.0125            0.117925               4  \n",
       "3767          0.062578              0.0125            0.117925               3  \n",
       "2496          0.069597              0.0125            0.037500               5  \n",
       "3770          0.088167              0.0250            0.093541               2  \n",
       "1103          0.053765              0.0125            0.067315               5  \n",
       "19            0.045928              0.0000            0.079057               3  \n",
       "1032          0.063738              0.0250            0.093541               5  \n",
       "2044          0.075000              0.0125            0.087500               3  \n",
       "3209          0.058962              0.0250            0.050000               4  \n",
       "1962          0.070986              0.0250            0.050000               4  \n",
       "1100          0.082443              0.0500            0.082916               5  \n",
       "660           0.043750              0.0125            0.067315               6  \n",
       "2560          0.063199              0.0125            0.087500               4  \n",
       "2018          0.100244              0.0000            0.079057               3  \n",
       "3309          0.060029              0.0125            0.067315               4  \n",
       "3148          0.088884             -0.0250            0.075000               4  \n",
       "2743          0.069104              0.0000            0.096825               5  \n",
       "2024          0.107756              0.0250            0.093541               5  \n",
       "1860          0.070503              0.0250            0.050000               7  \n",
       "1813          0.070503              0.0125            0.067315               6  \n",
       "1662          0.085525              0.0250            0.108972               6  \n",
       "1635          0.063199              0.0125            0.067315               4  \n",
       "2855          0.080828             -0.0250            0.108972               1  \n",
       "2498          0.091055              0.0250            0.093541               3  \n",
       "932           0.093175              0.0000            0.055902               3  \n",
       "1971          0.040625              0.0125            0.067315               4  \n",
       "3699          0.056682              0.0000            0.000000               3  \n",
       "1095          0.069877              0.0000            0.055902               4  \n",
       "133           0.064043             -0.0125            0.037500               4  \n",
       "3608          0.055902              0.0125            0.067315               6  \n",
       "3855          0.091643             -0.0250            0.156125               4  \n",
       "918           0.064043              0.0375            0.097628               4  \n",
       "2835          0.081490              0.0000            0.111803               6  \n",
       "1549          0.050389             -0.0125            0.037500               5  \n",
       "165           0.093750              0.0250            0.093541               3  \n",
       "2195          0.065551              0.0000            0.079057               7  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_group_sorted = all_group.sort_values(\"avg_weak_synergy\", ascending = False)\n",
    "all_group_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group.to_csv('10sim_NEW_all_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81921875, 0.819453125, 0.8228125000000001)\n",
      "(0.049299536873458547, 0.02613056441189848, 0.02945965196247233)\n",
      "(10.00125, 14.089999999999998, 12.9225)\n",
      "(2.1900681353556104, 1.7158161323405257, 1.4767595437307994)\n"
     ]
    }
   ],
   "source": [
    "homogenous_mean_acc = np.mean(homogeous_group_df['avg_accuracy'])\n",
    "fifty_mean_acc = np.mean(fifty_group['avg_accuracy'])\n",
    "hetero_mean_acc = np.mean(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_std_acc = np.std(homogeous_group_df['avg_accuracy'])\n",
    "fifty_std_acc = np.std(fifty_group['avg_accuracy'])\n",
    "hetero_std_acc = np.std(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_mean_tick = np.mean(homogeous_group_df['avg_n_tick'])\n",
    "fifty_mean_tick = np.mean(fifty_group['avg_n_tick'])\n",
    "hetero_mean_tick = np.mean(hetero_group['avg_n_tick'])\n",
    "\n",
    "homogenous_std_tick = np.std(homogeous_group_df['avg_n_tick'])\n",
    "fifty_std_tick = np.std(fifty_group['avg_n_tick'])\n",
    "hetero_std_tick = np.std(hetero_group['avg_n_tick'])\n",
    "\n",
    "print(tuple([homogenous_mean_acc, fifty_mean_acc, hetero_mean_acc]))\n",
    "print(tuple([homogenous_std_acc, fifty_std_acc, hetero_std_acc]))\n",
    "\n",
    "print(tuple([homogenous_mean_tick, fifty_mean_tick, hetero_mean_tick]))\n",
    "print(tuple([homogenous_std_tick, fifty_std_tick, hetero_std_tick]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
