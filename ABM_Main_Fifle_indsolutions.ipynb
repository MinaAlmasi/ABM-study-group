{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = pd.read_csv(\"pt_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ExScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.SeScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ThScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.JuScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                if i == 0 or i == 1:\n",
    "                    if student.Type[0] == \"E\":\n",
    "                        wrong_answer = 1\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[0] == \"I\":\n",
    "                        wrong_answer = 2\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 2 or i == 3:\n",
    "                    if student.Type[1] == \"N\":\n",
    "                        wrong_answer = 3\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[1] == \"S\":\n",
    "                        wrong_answer = 4\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 4 or i == 5:\n",
    "                    if student.Type[2] == \"T\":\n",
    "                        wrong_answer = 5\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[2] == \"F\":\n",
    "                        wrong_answer = 6\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                \n",
    "                if i == 6 or i == 7:\n",
    "                    if student.Type[3] == \"J\":\n",
    "                        wrong_answer = 7\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                    \n",
    "                    if student.Type[3] == \"P\":\n",
    "                        wrong_answer = 8\n",
    "                        Ind_Solution_lst.append(wrong_answer)\n",
    "                        Ind_Solution_attr_lst.append(wrong_answer)\n",
    "        \n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"ESTJ\"\n",
    "B = \"ISTJ\"\n",
    "agent_type_equality(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "student_list_test = [\"ESFP\", \"ISFP\", \"ISFP\", \"ISFP\"]\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.570474  0.848178  0.112188  0.351643  0.341645\n",
      "1    Bravo  ISFP  0.487612  0.628535  0.199841  0.451177  0.592122\n",
      "2  Charlie  ISFP  0.463291  0.752088  0.254007  0.498944  0.531920\n",
      "3    Delta  ISFP  0.366814  0.641523  0.135692  0.295249  0.439063\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(8, [1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 2, 3, 2, 5, 4, 6]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5, 2, 3, 2, 5, 4, 6],\n",
       " [1, 2, 2, 4, 6, 5, 4, 6],\n",
       " [1, 5, 2, 3, 2, 5, 4, 6],\n",
       " [1, 2, 2, 3, 2, 6, 4, 6]]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [1, 5, 2, 3, 2, 5, 4, 6]\n",
      "Bravo [1, 2, 2, 4, 6, 5, 4, 6]\n",
      "Charlie [1, 5, 2, 3, 2, 5, 4, 6]\n",
      "Delta [1, 2, 2, 3, 2, 6, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 1.0\n",
      "Bravo 0.625\n",
      "Charlie 1.0\n",
      "Delta 0.75\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 5, 2, 3, 2, 5, 4, 6], 23, True)\n",
      "[[1, 5, 2, 3, 2, 5, 4, 6], [1, 2, 2, 4, 6, 5, 4, 6], [1, 5, 2, 3, 2, 5, 4, 6], [1, 2, 2, 3, 2, 6, 4, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ind, all_group = abm_model(condition = all_groups, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 8, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 10\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>19.3</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.177218</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.049390</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.087500</td>\n",
       "      <td>0.144428</td>\n",
       "      <td>-0.2250</td>\n",
       "      <td>0.165831</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.408319</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.085009</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.147902</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.193171</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.531798</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.111847</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.002498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.1750</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.160078</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.193171</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>-0.087500</td>\n",
       "      <td>0.129452</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.147902</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.244994</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.137677</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3.008322</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>0.128239</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>0.141973</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.115244</td>\n",
       "      <td>18.4</td>\n",
       "      <td>2.537716</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.187083</td>\n",
       "      <td>18.4</td>\n",
       "      <td>2.905168</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.184349</td>\n",
       "      <td>-0.2625</td>\n",
       "      <td>0.197247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.210654</td>\n",
       "      <td>18.4</td>\n",
       "      <td>2.374868</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.137784</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.160078</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2.051828</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.139894</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.127475</td>\n",
       "      <td>18.3</td>\n",
       "      <td>3.407345</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.126591</td>\n",
       "      <td>-0.1500</td>\n",
       "      <td>0.134629</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2.968164</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>18.3</td>\n",
       "      <td>3.163858</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.071329</td>\n",
       "      <td>-0.1500</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2.193171</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.128087</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>18.2</td>\n",
       "      <td>3.370460</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.139754</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.891366</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>-0.2250</td>\n",
       "      <td>0.183712</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.139194</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.993326</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>-0.059375</td>\n",
       "      <td>0.118132</td>\n",
       "      <td>-0.2250</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "1111  ESTJ  ISTJ    INTP  INTP        0.8375      0.112500        19.3   \n",
       "2293  ISTJ  INFP    INFP  ENTP        0.7125      0.177218        19.0   \n",
       "1639  ISFJ  ISTJ    INFP  ENTP        0.7250      0.093541        19.0   \n",
       "1733  ISFJ  ENFP    INFJ  ISTP        0.8750      0.147902        18.7   \n",
       "3737  ENTJ  ESFP    ISFP  ISFP        0.8375      0.112500        18.7   \n",
       "2650  ENFP  ENFJ    ESTP  ISFP        0.7625      0.130504        18.7   \n",
       "514   ESFJ  ENFP    INTP  ISTP        0.7000      0.160078        18.7   \n",
       "3738  ENTJ  ESFP    ISFP  ISTP        0.8375      0.125623        18.6   \n",
       "2751  ENFP  INFJ    ESTP  ISTP        0.7750      0.145774        18.5   \n",
       "1862  ISFJ  INFP    ENTP  ISTP        0.8125      0.115244        18.4   \n",
       "1327  ESTJ  INFP    ESTP  ISTP        0.6750      0.187083        18.4   \n",
       "2341  ISTJ  INFP    ESTP  ISFP        0.7000      0.210654        18.4   \n",
       "238   ESFJ  ESTJ    INTP  ESTP        0.8000      0.127475        18.3   \n",
       "1196  ESTJ  ENFP    INTJ  ESFP        0.8000      0.127475        18.3   \n",
       "2344  ISTJ  INFP    ISFP  ISTP        0.7625      0.162500        18.3   \n",
       "2338  ISTJ  INFP    ESFP  ISFP        0.7875      0.097628        18.3   \n",
       "887   ESTJ  ESTJ    INFP  ESFP        0.8500      0.108972        18.3   \n",
       "886   ESTJ  ESTJ    INFP  INTJ        0.8125      0.083853        18.2   \n",
       "779   ESFJ  INTP    ISFP  ISTP        0.6875      0.139754        18.2   \n",
       "3824  INTJ  ESFP    ESFP  ISTP        0.6750      0.139194        18.2   \n",
       "\n",
       "      std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "1111    1.417745            0.3       0.458258          0.009375   \n",
       "2293    2.049390            0.3       0.458258         -0.087500   \n",
       "1639    2.408319            0.3       0.458258         -0.062500   \n",
       "1733    2.193171            0.4       0.489898          0.065625   \n",
       "3737    2.531798            0.3       0.458258          0.021875   \n",
       "2650    2.002498            0.3       0.458258         -0.015625   \n",
       "514     2.193171            0.4       0.489898         -0.087500   \n",
       "3738    2.244994            0.5       0.500000          0.021875   \n",
       "2751    3.008322            0.3       0.458258         -0.018750   \n",
       "1862    2.537716            0.7       0.458258          0.031250   \n",
       "1327    2.905168            0.3       0.458258         -0.093750   \n",
       "2341    2.374868            0.4       0.489898         -0.075000   \n",
       "238     2.051828            0.7       0.458258          0.012500   \n",
       "1196    3.407345            0.2       0.400000          0.021875   \n",
       "2344    2.968164            0.6       0.489898          0.037500   \n",
       "2338    3.163858            0.5       0.500000          0.009375   \n",
       "887     2.193171            0.5       0.500000          0.056250   \n",
       "886     3.370460            0.5       0.500000          0.006250   \n",
       "779     2.891366            0.7       0.458258         -0.062500   \n",
       "3824    2.993326            0.4       0.489898         -0.059375   \n",
       "\n",
       "      std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "1111          0.121071             -0.0875            0.125623               5  \n",
       "2293          0.144428             -0.2250            0.165831               5  \n",
       "1639          0.085009             -0.2000            0.100000               7  \n",
       "1733          0.114777             -0.0875            0.137500               6  \n",
       "3737          0.111847             -0.1250            0.125000               5  \n",
       "2650          0.114607             -0.1750            0.127475               5  \n",
       "514           0.129452             -0.2500            0.147902               7  \n",
       "3738          0.137677             -0.1125            0.130504               6  \n",
       "2751          0.128239             -0.1375            0.141973               7  \n",
       "1862          0.101743             -0.1375            0.103833               6  \n",
       "1327          0.184349             -0.2625            0.197247               5  \n",
       "2341          0.137784             -0.2000            0.160078               5  \n",
       "238           0.139894             -0.1375            0.103833               5  \n",
       "1196          0.126591             -0.1500            0.134629               7  \n",
       "2344          0.127934             -0.1000            0.175000               4  \n",
       "2338          0.071329             -0.1500            0.122474               4  \n",
       "887           0.109865             -0.0625            0.128087               6  \n",
       "886           0.076291             -0.0875            0.080039               6  \n",
       "779           0.134774             -0.2250            0.183712               5  \n",
       "3824          0.118132             -0.2250            0.145774               6  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_group_sorted = all_group.sort_values(\"avg_n_tick\", ascending = False)\n",
    "all_group_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group.to_csv('10sim_NEW_all_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.81921875, 0.819453125, 0.8228125000000001)\n",
      "(0.049299536873458547, 0.02613056441189848, 0.02945965196247233)\n",
      "(10.00125, 14.089999999999998, 12.9225)\n",
      "(2.1900681353556104, 1.7158161323405257, 1.4767595437307994)\n"
     ]
    }
   ],
   "source": [
    "homogenous_mean_acc = np.mean(homogeous_group_df['avg_accuracy'])\n",
    "fifty_mean_acc = np.mean(fifty_group['avg_accuracy'])\n",
    "hetero_mean_acc = np.mean(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_std_acc = np.std(homogeous_group_df['avg_accuracy'])\n",
    "fifty_std_acc = np.std(fifty_group['avg_accuracy'])\n",
    "hetero_std_acc = np.std(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_mean_tick = np.mean(homogeous_group_df['avg_n_tick'])\n",
    "fifty_mean_tick = np.mean(fifty_group['avg_n_tick'])\n",
    "hetero_mean_tick = np.mean(hetero_group['avg_n_tick'])\n",
    "\n",
    "homogenous_std_tick = np.std(homogeous_group_df['avg_n_tick'])\n",
    "fifty_std_tick = np.std(fifty_group['avg_n_tick'])\n",
    "hetero_std_tick = np.std(hetero_group['avg_n_tick'])\n",
    "\n",
    "print(tuple([homogenous_mean_acc, fifty_mean_acc, hetero_mean_acc]))\n",
    "print(tuple([homogenous_std_acc, fifty_std_acc, hetero_std_acc]))\n",
    "\n",
    "print(tuple([homogenous_mean_tick, fifty_mean_tick, hetero_mean_tick]))\n",
    "print(tuple([homogenous_std_tick, fifty_std_tick, hetero_std_tick]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
