{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Based Model: Main Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Notes \n",
    "* Draw Students with values within the four dimensions \n",
    "* Function that creates a study group (draw 4 students) -> Measure homogeniety \n",
    "* Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Study Groups that are to be Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ESFJ', 'ESFJ', 'ESFJ', 'ESFJ']\n",
      "['ESTJ', 'ESTJ', 'ESTJ', 'ESTJ']\n",
      "['ISFJ', 'ISFJ', 'ISFJ', 'ISFJ']\n",
      "['ISTJ', 'ISTJ', 'ISTJ', 'ISTJ']\n",
      "['ENFP', 'ENFP', 'ENFP', 'ENFP']\n",
      "['ENFJ', 'ENFJ', 'ENFJ', 'ENFJ']\n",
      "['INFP', 'INFP', 'INFP', 'INFP']\n",
      "['INFJ', 'INFJ', 'INFJ', 'INFJ']\n",
      "['ENTP', 'ENTP', 'ENTP', 'ENTP']\n",
      "['ENTJ', 'ENTJ', 'ENTJ', 'ENTJ']\n",
      "['INTP', 'INTP', 'INTP', 'INTP']\n",
      "['INTJ', 'INTJ', 'INTJ', 'INTJ']\n",
      "['ESFP', 'ESFP', 'ESFP', 'ESFP']\n",
      "['ESTP', 'ESTP', 'ESTP', 'ESTP']\n",
      "['ISFP', 'ISFP', 'ISFP', 'ISFP']\n",
      "['ISTP', 'ISTP', 'ISTP', 'ISTP']\n"
     ]
    }
   ],
   "source": [
    "homogenous = pd.read_csv(\"Conditions/Homogenous.csv\")\n",
    "fiftyfifty = pd.read_csv(\"Conditions/FiftyFifty.csv\")\n",
    "heterogenous = pd.read_csv(\"Conditions/Heterogenous.csv\")\n",
    "\n",
    "\n",
    "for i in (range(len(homogenous.index))):\n",
    "    print(list(homogenous.iloc[i][1:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sampler(size):\n",
    "    '''\n",
    "    sample a number of random numbers from the beta distribution\n",
    "    '''\n",
    "    max_vals = []\n",
    "    min_vals = []\n",
    "\n",
    "    beta_dist = rnd.beta(1.5, 1.5, size)\n",
    "\n",
    "    for i in range(size):\n",
    "        if beta_dist[i] >= 0.5:\n",
    "            max_vals.append(beta_dist[i])\n",
    "        else:\n",
    "            min_vals.append(beta_dist[i])\n",
    "    \n",
    "    return max_vals, min_vals\n",
    "\n",
    "max_vals, min_vals = n_sampler(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(studygroup, student_list):\n",
    "    '''\n",
    "    function to collect data from the simulation\n",
    "    '''\n",
    "    Name_list = []\n",
    "    extraversion_list = []\n",
    "    sensing_list = []\n",
    "    thinking_list = []\n",
    "    judging_list = []\n",
    "    academic_list = []\n",
    "    \n",
    "    for student in studygroup:\n",
    "        Name_list.append(student.Name)\n",
    "        extraversion_list.append(student.ExScore)\n",
    "        sensing_list.append(student.SeScore) \n",
    "        thinking_list.append(student.ThScore)\n",
    "        judging_list.append(student.JuScore)\n",
    "        academic_list.append(student.Academic_Skill)\n",
    "\n",
    "    data = pd.DataFrame({'Name': Name_list, \n",
    "                        'type': student_list, \n",
    "                        'E/I': extraversion_list, \n",
    "                        'S/N': sensing_list,\n",
    "                        'T/F': thinking_list,\n",
    "                        'J/P': judging_list, \n",
    "                        'Academic': academic_list})\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Study Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Students ##\n",
    "class Student():\n",
    "    def __init__(self, Name, Ex, Se, Th, Ju):\n",
    "        self.Name  = Name\n",
    "\n",
    "        ## Personality Traits ##\n",
    "        self.Ex = Ex #Extraversion vs Introversion dimension\n",
    "        self.Se = Se #Sensing vs Intuition dimension\n",
    "        self.Th = Th #Thinking vs Feeling dimension\n",
    "        self.Ju = Ju #Judging vs Perceiving dimension\n",
    "        self.Type = Ex + Se + Th + Ju\n",
    "\n",
    "        ## Personality Scores calculated with the personality() function##\n",
    "        self.ExScore = 0\n",
    "        self.SeScore = 0\n",
    "        self.ThScore = 0\n",
    "        self.JuScore = 0\n",
    "        \n",
    "        self.Scores = [] #list of all personality scores\n",
    "\n",
    "        ## Academic Skills ##\n",
    "        self.Academic_Skill = 0\n",
    "\n",
    "        ## Own Solution ##\n",
    "        self.Ind_Solution = []\n",
    "\n",
    "def personality(student):\n",
    "    # Extraversion vs. Introversion\n",
    "    if student.Ex == \"E\":\n",
    "        student.ExScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ExScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Sensing vs. Intuition\n",
    "    if student.Se == \"S\":\n",
    "        student.SeScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.SeScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    # Thinking vs. Feeling\n",
    "    if student.Th == \"T\":\n",
    "        student.ThScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.ThScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "\n",
    "    # Judging vs. Perceiving\n",
    "    if student.Ju == \"J\":\n",
    "        student.JuScore = max_vals[0]\n",
    "        del max_vals[0]\n",
    "    else:\n",
    "        student.JuScore = min_vals[0]\n",
    "        del min_vals[0]\n",
    "    \n",
    "    student.Scores = [student.ExScore, student.SeScore, student.ThScore, student.JuScore]\n",
    "\n",
    "def skills(student):\n",
    "    student.Academic_Skill = (1-student.SeScore)*0.33 + student.JuScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)\n",
    "    student.Compromising = (1-student.ThScore)*0.33 + student.ExScore*0.33 + (rnd.beta(8, 2, 1)[0]*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StudyGroup(student_list):\n",
    "    '''\n",
    "    Create a study group of students\n",
    "    '''\n",
    "    studygroup = []\n",
    "    names = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\"]\n",
    "\n",
    "    for i in range(len(student_list)):\n",
    "        student = Student(names[i], student_list[i][0], student_list[i][1], student_list[i][2], student_list[i][3])\n",
    "        personality(student)\n",
    "        skills(student)\n",
    "        studygroup.append(student)\n",
    "    \n",
    "    return data_collect(studygroup, student_list), studygroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating True Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution_generator(n_part_exercises, range_elements):\n",
    "    '''\n",
    "    create a list of random numbers that will serve as the true solution that the agents need to find \n",
    "    '''\n",
    "    true_solution = []\n",
    "    for i in range(n_part_exercises):\n",
    "        true_solution.append(random.randint(range_elements[0], range_elements[1]))\n",
    "\n",
    "    return true_solution, range_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Individual Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_solutions_generator(studygroup, true_solution, range_elements):\n",
    "    '''\n",
    "    #function to calculate the individual solutions of the agents given a study group dataframe and a true solution\n",
    "    '''\n",
    "    \n",
    "    all_solutions = []\n",
    "\n",
    "    for student in studygroup[1]: # loop for each individual\n",
    "        Ind_Solution_lst = []\n",
    "        Ind_Solution_attr_lst = []\n",
    "        \n",
    "        for i in range(len(true_solution)): # loop for each part-exercise\n",
    "            coin_toss = np.random.binomial(1, (student.Academic_Skill*0.5) + 0.5, 1)[0] # biased-coin flip\n",
    "            if coin_toss == 1:\n",
    "                Ind_Solution_lst.append(true_solution[i])\n",
    "                Ind_Solution_attr_lst.append(true_solution[i])\n",
    "            else:\n",
    "                if student.Type[0] == \"E\":\n",
    "                    wrong_answer = 1\n",
    "                    Ind_Solution_lst.append(wrong_answer)\n",
    "                    Ind_Solution_attr_lst.append(wrong_answer)\n",
    "                if student.Type[0] == \"I\":\n",
    "                    wrong_answer = 2\n",
    "                    Ind_Solution_lst.append(wrong_answer)\n",
    "                    Ind_Solution_attr_lst.append(wrong_answer)\n",
    "        \n",
    "        all_solutions.append(Ind_Solution_lst)\n",
    "        student.Ind_Solution = Ind_Solution_attr_lst\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_type_equality(agent_a, agent_b):\n",
    "    equality_score = 0 # number from 0 to 1\n",
    "    for i in range(4):\n",
    "        if agent_a[i] == agent_b[i]:\n",
    "            equality_score += 0.25\n",
    "    return equality_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"ESTJ\"\n",
    "B = \"ISTJ\"\n",
    "agent_type_equality(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workflow notes\n",
    "1. Who presents their solution e.g. agent A presents their solution to agent B, C, D -> THE PROPOSED SOLUTION\n",
    "    -> Based on Extraversion score (Highest extraversion score is the most likely to present their solution)\n",
    "2. According to an Agreeableness score (Social score for now) of the other agents (and maybe a Trustworthiness score of agent proposing), agents will update their solution\n",
    "3. The solutions of the agents will be checked, if all they agree, this is their final solution. If not, the process will be repeated for a max of X ticks. If the groups do not converge, an accuracy score will still be calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_solution(studygroup, max_ticks):\n",
    "    max_ticks = max_ticks #turns in the simulation\n",
    "    n_ticks = 0\n",
    "    consensus = False\n",
    "    \n",
    "    # extracting all 4 students\n",
    "    Alfa = studygroup[1][0]\n",
    "    Bravo = studygroup[1][1]\n",
    "    Charlie = studygroup[1][2]\n",
    "    Delta = studygroup[1][3]\n",
    "\n",
    "    student_list = [Alfa, Bravo, Charlie, Delta]\n",
    "    individual_solutions = [Alfa.Ind_Solution, Bravo.Ind_Solution, Charlie.Ind_Solution, Delta.Ind_Solution]\n",
    "\n",
    "    while (n_ticks != max_ticks):\n",
    "        # Starting a Round\n",
    "        presenter_name = random.choices([Alfa.Name, Bravo.Name, Charlie.Name, Delta.Name], weights = [Alfa.ExScore, Bravo.ExScore, Charlie.ExScore, Delta.ExScore], k = 1)[0] # selecting the presenter of the round based on weighted random draw from extraversion scores\n",
    "        \n",
    "        Proposed_Solution = eval(presenter_name).Ind_Solution\n",
    "        #print(n_ticks, presenter_name, Proposed_Solution)\n",
    "\n",
    "        for student in student_list:\n",
    "            if student == eval(presenter_name):\n",
    "                continue\n",
    "            \n",
    "            similarity_score = agent_type_equality(eval(presenter_name).Type, student.Type) # evaluate how equal the two agents are in personality. This bases the coinflip\n",
    "            similarity_coin_toss = np.random.binomial(1, similarity_score, 1)[0]\n",
    "            \n",
    "            if similarity_coin_toss == 0:\n",
    "                coin_toss = np.random.binomial(1, 0.5, 1)[0] # giving a 50% chance of not ending loop if you lose on similarity score.\n",
    "                if coin_toss == 1:\n",
    "                    continue\n",
    "                \n",
    "            for i in range(len(Proposed_Solution)): # looping through all part-exercises and evaluating against proposed solution.\n",
    "                coin_toss = np.random.binomial(1, (student.Compromising*0.25 + eval(presenter_name).Academic_Skill*0.25), 1)[0] #high social skill has a greater chance of accepting the proposal and if the proposer has higher academic skill.\n",
    "                if coin_toss == 1:\n",
    "                    student.Ind_Solution[i] = Proposed_Solution[i]\n",
    "                else:\n",
    "                    student.Ind_Solution[i] = student.Ind_Solution[i]\n",
    "\n",
    "        n_ticks += 1 #adding a tick to the simulation\n",
    "\n",
    "        if all(x==individual_solutions[0] for x in individual_solutions): # initializes a break of while-loop if consensus has been reached (i.e. all solutions are the same)\n",
    "            consensus = True\n",
    "            break\n",
    "    \n",
    "    if consensus == True:\n",
    "        final_group_solution = individual_solutions[0] # take one of the solutions from the group if they are all the same\n",
    "    \n",
    "    if consensus == False:\n",
    "        final_group_solution = Proposed_Solution\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Number of iterations: \" + str(n_ticks))\n",
    "    return final_group_solution, n_ticks, consensus # returns their collective solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_evaluator(proposed_solution, true_solution):\n",
    "    correct_part_exercise = 0\n",
    "    wrong_part_exercise = 0\n",
    "\n",
    "    for i in range(len(true_solution)):\n",
    "        if proposed_solution[i] == true_solution[i]:\n",
    "            correct_part_exercise += 1\n",
    "        else:\n",
    "            wrong_part_exercise += 1\n",
    "\n",
    "    return correct_part_exercise / (correct_part_exercise + wrong_part_exercise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_degree(individual_solution, group_solution):\n",
    "    '''\n",
    "    #function to calculate the adaptation degree of the agents\n",
    "    '''\n",
    "    adapted = 0\n",
    "    not_adapted = 0\n",
    "\n",
    "    for i in range(len(individual_solution)):\n",
    "        if individual_solution[i] == group_solution[i]:\n",
    "            not_adapted += 1\n",
    "        else:\n",
    "            adapted += 1\n",
    "    \n",
    "    adaptation = adapted / (adapted + not_adapted)\n",
    "\n",
    "    return adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synergy_calculator(individual_accuracies, group_accuracy):\n",
    "    '''\n",
    "    #function to calculate the gain of the agents\n",
    "    '''\n",
    "    avg_of_indi_accuracy = np.mean(individual_accuracies)\n",
    "    max_of_indi_accuracy = np.max(individual_accuracies)\n",
    "    \n",
    "    weak_synergy = group_accuracy - avg_of_indi_accuracy\n",
    "    strong_synergy = group_accuracy - max_of_indi_accuracy\n",
    "\n",
    "    return weak_synergy, strong_synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_score_calculator(student_list):\n",
    "    diversity_score = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        if (student_list[0][i] == student_list[1][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 0\n",
    "        elif (student_list[0][i] == student_list[1][i] == student_list[2][i]) or (student_list[0][i] == student_list[1][i] == student_list[3][i]) or (student_list[1][i] == student_list[2][i] == student_list[3][i]) or (student_list[0][i] == student_list[2][i] == student_list[3][i]):\n",
    "            diversity_score += 1\n",
    "        else:\n",
    "            diversity_score += 2\n",
    "    \n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Study Group\n",
    "student_list_test = [\"ESFP\", \"ISFP\", \"ISFP\", \"ISFP\"]\n",
    "studygroup1 = StudyGroup(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_score_calculator(student_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  type       E/I       S/N       T/F       J/P  Academic\n",
      "0     Alfa  ESFP  0.551934  0.617539  0.178827  0.301906  0.445872\n",
      "1    Bravo  ISFP  0.129382  0.585067  0.329284  0.426310  0.531059\n",
      "2  Charlie  ISFP  0.382529  0.825667  0.304898  0.306537  0.465312\n",
      "3    Delta  ISFP  0.191405  0.536864  0.366709  0.383000  0.565813\n"
     ]
    }
   ],
   "source": [
    "# Seeing their Generated Personality Scores\n",
    "print(studygroup1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a True Solution\n",
    "true_solution_test = true_solution_generator(10, [1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 8, 3, 7, 1, 1, 1, 8]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the True Solution\n",
    "true_solution_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 2, 1, 3, 1, 1, 1, 1, 8],\n",
       " [2, 3, 2, 2, 3, 7, 1, 1, 2, 2],\n",
       " [1, 2, 2, 8, 2, 7, 2, 1, 1, 8],\n",
       " [1, 2, 2, 2, 2, 2, 2, 1, 1, 2]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Individual Solutions\n",
    "all_solutions = individual_solutions_generator(studygroup1, true_solution_test[0], true_solution_test[1])\n",
    "all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa [1, 3, 2, 1, 3, 1, 1, 1, 1, 8]\n",
      "Bravo [2, 3, 2, 2, 3, 7, 1, 1, 2, 2]\n",
      "Charlie [1, 2, 2, 8, 2, 7, 2, 1, 1, 8]\n",
      "Delta [1, 2, 2, 2, 2, 2, 2, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Printing Individual Solutions\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, student.Ind_Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa 0.8\n",
      "Bravo 0.6\n",
      "Charlie 0.7\n",
      "Delta 0.4\n"
     ]
    }
   ],
   "source": [
    "# Printing Indivudal Accuracies\n",
    "for student in studygroup1[1]:\n",
    "    print(student.Name, solution_evaluator(student.Ind_Solution, true_solution_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Group Solution\n",
    "group_solution = collaborative_solution(studygroup1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 3, 2, 1, 3, 1, 2, 1, 2, 2], 21, True)\n",
      "[[1, 3, 2, 1, 3, 1, 1, 1, 1, 8], [2, 3, 2, 2, 3, 7, 1, 1, 2, 2], [1, 2, 2, 8, 2, 7, 2, 1, 1, 8], [1, 2, 2, 2, 2, 2, 2, 1, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(group_solution)\n",
    "print(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Printing Group Accuracy\n",
    "accuracy = solution_evaluator(group_solution[0], true_solution_test[0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_degree(all_solutions[0], group_solution[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_run(student_list: list, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    '''\n",
    "    function to run one simulation of a study group completing the exercise (from individual to group solution)\n",
    "    '''\n",
    "\n",
    "    #### ---- LISTS ---- #### \n",
    "    ## ---- group level ---- ###\n",
    "    group_accuracy_list = []\n",
    "    n_tick_list = []\n",
    "    weak_synergy_list = []\n",
    "    strong_synergy_list = []\n",
    "    consensus_list = []\n",
    "\n",
    "    ## ---- individual level ---- ###\n",
    "    alfa_accuracy_list = []\n",
    "    beta_accuracy_list = []\n",
    "    charlie_accuracy_list = []\n",
    "    delta_accuracy_list = []\n",
    "\n",
    "    alfa_adaptation_list = []\n",
    "    beta_adaptation_list = []\n",
    "    charlie_adaptation_list = []\n",
    "    delta_adaptation_list = []\n",
    "\n",
    "    # ---- starting simulation ---- #\n",
    "    for i in range(n_simulations):\n",
    "        ## giving the study group personality values and skills ##\n",
    "        studygroup = StudyGroup(student_list)\n",
    "        \n",
    "        ## ---- SOLUTIONS ---- ##\n",
    "        ## generating the true solution ## \n",
    "        true_solution = true_solution_generator(n_part_exercises, range_solution)\n",
    "\n",
    "        ## generating individual solutions ##\n",
    "        all_solutions = individual_solutions_generator(studygroup, true_solution[0], true_solution[1])\n",
    "\n",
    "        ## evaluating own solutions ##        \n",
    "        alfa_accuracy = solution_evaluator(all_solutions[0], true_solution[0])\n",
    "        beta_accuracy = solution_evaluator(all_solutions[1], true_solution[0])\n",
    "        charlie_accuracy = solution_evaluator(all_solutions[2], true_solution[0])\n",
    "        delta_accuracy = solution_evaluator(all_solutions[3], true_solution[0])\n",
    "\n",
    "        all_accuracies = [alfa_accuracy, beta_accuracy, charlie_accuracy, delta_accuracy]\n",
    "        \n",
    "        alfa_accuracy_list.append(alfa_accuracy)\n",
    "        beta_accuracy_list.append(beta_accuracy)\n",
    "        charlie_accuracy_list.append(charlie_accuracy)\n",
    "        delta_accuracy_list.append(delta_accuracy)\n",
    "\n",
    "        ## generating group solution ##\n",
    "        group_solution = collaborative_solution(studygroup, max_ticks)\n",
    "        n_tick_list.append(group_solution[1]) # appending the number of ticks\n",
    "        consensus_list.append(group_solution[2]) # appending whether a consensus was reached or not\n",
    "        \n",
    "        ## ---- MEASURES ---- ##\n",
    "        ## calculating degree of adaptation ## \n",
    "        alfa_adaption = adaptation_degree(all_solutions[0], group_solution[0])\n",
    "        beta_adaption = adaptation_degree(all_solutions[1], group_solution[0])\n",
    "        charlie_adaption = adaptation_degree(all_solutions[2], group_solution[0])\n",
    "        delta_adaption = adaptation_degree(all_solutions[3], group_solution[0])\n",
    "\n",
    "        alfa_adaptation_list.append(alfa_adaption)\n",
    "        beta_adaptation_list.append(beta_adaption)\n",
    "        charlie_adaptation_list.append(charlie_adaption)\n",
    "        delta_adaptation_list.append(delta_adaption)\n",
    "\n",
    "        ## calculating the accuracy of the group solution ##\n",
    "        group_accuracy = solution_evaluator(group_solution[0], true_solution[0])\n",
    "        group_accuracy_list.append(group_accuracy) #appending the group accuracies\n",
    "\n",
    "        # calculating the gain from the individual solutions to the group solution\n",
    "        weak_synergy, strong_synergy = synergy_calculator(all_accuracies, group_accuracy)\n",
    "        weak_synergy_list.append(weak_synergy)\n",
    "        strong_synergy_list.append(strong_synergy)\n",
    "        \n",
    "\n",
    "    \n",
    "    diversity_score = diversity_score_calculator(student_list)\n",
    "\n",
    "    ## calculating the mean and standard deivations ##\n",
    "    # ---- group level ---- #\n",
    "    avg_group_accuracy = np.mean(group_accuracy_list)\n",
    "    std_group_accuracy = np.std(group_accuracy_list)\n",
    "    \n",
    "    avg_group_n_tick = np.mean(n_tick_list)\n",
    "    std_group_n_tick = np.std(n_tick_list)\n",
    "\n",
    "    avg_consensus = np.mean(consensus_list)\n",
    "    std_consensus = np.std(consensus_list)\n",
    "\n",
    "    avg_weak_synergy  = np.mean(weak_synergy_list)\n",
    "    std_weak_synergy = np.std(weak_synergy_list)\n",
    "\n",
    "    avg_strong_synergy  = np.mean(strong_synergy_list)\n",
    "    std_strong_synergy = np.std(strong_synergy_list)\n",
    "    \n",
    "    # ---- individual level ---- #\n",
    "    avg_alfa_accuracy = np.mean(alfa_accuracy_list)\n",
    "    std_alfa_accuracy = np.std(alfa_accuracy_list)\n",
    "\n",
    "    avg_beta_accuracy = np.mean(beta_accuracy_list)\n",
    "    std_beta_accuracy = np.std(beta_accuracy_list)\n",
    "\n",
    "    avg_charlie_accuracy = np.mean(charlie_accuracy_list)\n",
    "    std_charlie_accuracy = np.std(charlie_accuracy_list)\n",
    "\n",
    "    avg_delta_accuracy = np.mean(delta_accuracy_list)\n",
    "    std_delta_accuracy = np.std(delta_accuracy_list)\n",
    "\n",
    "    avg_alfa_adaptation = np.mean(alfa_adaptation_list)\n",
    "    avg_beta_adaptation = np.mean(beta_adaptation_list)\n",
    "    avg_charlie_adaptation = np.mean(charlie_adaptation_list)\n",
    "    avg_delta_adaptation = np.mean(delta_adaptation_list)\n",
    "    \n",
    "    ## dictionaries ## \n",
    "    exercise_run_dict_group = {\n",
    "    'alfa': student_list[0], \n",
    "    'beta':student_list[1], \n",
    "    'charlie':student_list[2], \n",
    "    'delta':student_list[3], \n",
    "    'avg_accuracy': avg_group_accuracy, \n",
    "    'std_accuracy': std_group_accuracy, \n",
    "    'avg_n_tick': avg_group_n_tick, \n",
    "    'std_n_tick': std_group_n_tick, \n",
    "    'avg_consensus': avg_consensus,\n",
    "    'std_consensus': std_consensus,\n",
    "    'avg_weak_synergy': avg_weak_synergy,\n",
    "    'std_weak_synergy': std_weak_synergy, \n",
    "    'avg_strong_synergy': avg_strong_synergy,\n",
    "    'std_strong_synergy': std_strong_synergy,\n",
    "    'diversity_score': diversity_score}\n",
    "\n",
    "    exercise_run_list_ind = list(zip(student_list, \n",
    "                                    [student_list, student_list, student_list, student_list], \n",
    "                                    [avg_alfa_accuracy, avg_beta_accuracy, avg_charlie_accuracy, avg_delta_accuracy],\n",
    "                                    [std_alfa_accuracy, std_beta_accuracy, std_charlie_accuracy, std_delta_accuracy], \n",
    "                                    [avg_alfa_adaptation, avg_beta_adaptation, avg_charlie_adaptation, avg_delta_adaptation]))\n",
    "    \n",
    "    return exercise_run_dict_group, exercise_run_list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abm_model(condition, max_ticks: int, n_part_exercises: int, range_solution: list, n_simulations: int):\n",
    "    condition_group_df = pd.DataFrame(columns = ['alfa', 'beta', 'charlie', 'delta', 'avg_accuracy', 'std_accuracy', 'avg_n_tick', 'std_n_tick', 'avg_consensus', 'std_consensus', 'avg_weak_synergy', 'std_weak_synergy', 'avg_strong_synergy', 'std_strong_synergy', 'diversity_score'])\n",
    "    condition_ind_df = pd.DataFrame(columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        \n",
    "    for i in (range(len(condition.index))):\n",
    "        student_list = list(condition.iloc[i][1:5])\n",
    "        \n",
    "        ## Getting data frames for the group and individual levels ##\n",
    "        exercise_run_dict_group, exercise_run_list_ind = exercise_run(student_list, max_ticks, n_part_exercises, range_solution, n_simulations) #creating dictionary\n",
    "        \n",
    "        exercise_run_group_df = pd.DataFrame(exercise_run_dict_group, index = [i]) #creating dataframe\n",
    "        condition_group_df = pd.concat([condition_group_df, exercise_run_group_df], ignore_index = True) #concatenating dataframes\n",
    "        \n",
    "        exercise_run_ind_df = pd.DataFrame(exercise_run_list_ind, columns=['type', 'studygroup', 'avg_accuracy', 'std_accuracy', 'avg_adaptation']) #'avg_accuracy', 'contribution', 'n_presentations'])\n",
    "        condition_ind_df = pd.concat([condition_ind_df, exercise_run_ind_df], ignore_index = True)\n",
    "\n",
    "    return condition_ind_df, condition_group_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogenous_ind_df, homogeous_group_df = abm_model(condition = homogenous, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>studygroup</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_adaptation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>[INFJ, INFJ, INFJ, INFJ]</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.096431</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>[ENFJ, ENFJ, ENFJ, ENFJ]</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.106108</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>[ENTJ, ENTJ, ENTJ, ENTJ]</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.109886</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>[INFJ, INFJ, INFJ, INFJ]</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.113649</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>[INFJ, INFJ, INFJ, INFJ]</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.103976</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ESTP, ESTP, ESTP, ESTP]</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.135041</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ESTP, ESTP, ESTP, ESTP]</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ESTP, ESTP, ESTP, ESTP]</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.147821</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>[ISTP, ISTP, ISTP, ISTP]</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.129908</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>[ESFP, ESFP, ESFP, ESFP]</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                studygroup  avg_accuracy  std_accuracy  avg_adaptation\n",
       "30  INFJ  [INFJ, INFJ, INFJ, INFJ]         0.899      0.096431           0.132\n",
       "22  ENFJ  [ENFJ, ENFJ, ENFJ, ENFJ]         0.879      0.106108           0.133\n",
       "37  ENTJ  [ENTJ, ENTJ, ENTJ, ENTJ]         0.885      0.109886           0.138\n",
       "29  INFJ  [INFJ, INFJ, INFJ, INFJ]         0.878      0.113649           0.139\n",
       "28  INFJ  [INFJ, INFJ, INFJ, INFJ]         0.883      0.103976           0.146\n",
       "..   ...                       ...           ...           ...             ...\n",
       "55  ESTP  [ESTP, ESTP, ESTP, ESTP]         0.742      0.135041           0.267\n",
       "52  ESTP  [ESTP, ESTP, ESTP, ESTP]         0.783      0.129657           0.268\n",
       "54  ESTP  [ESTP, ESTP, ESTP, ESTP]         0.757      0.147821           0.270\n",
       "60  ISTP  [ISTP, ISTP, ISTP, ISTP]         0.782      0.129908           0.278\n",
       "50  ESFP  [ESFP, ESFP, ESFP, ESFP]         0.738      0.135484           0.285\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_homogenous = homogeous_group_df.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_homogenous\n",
    "\n",
    "homogenous_ind_df.sort_values(\"avg_adaptation\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_ind, fifty_group = abm_model(condition = fiftyfifty, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.127734</td>\n",
       "      <td>16.52</td>\n",
       "      <td>4.215400</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.497494</td>\n",
       "      <td>-1.750000e-03</td>\n",
       "      <td>0.108585</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.124097</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.130610</td>\n",
       "      <td>17.11</td>\n",
       "      <td>3.929109</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>-3.750000e-02</td>\n",
       "      <td>0.111664</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.134625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>15.65</td>\n",
       "      <td>4.879293</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>-4.500000e-03</td>\n",
       "      <td>0.117334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>0.124944</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.117473</td>\n",
       "      <td>15.26</td>\n",
       "      <td>5.007235</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.482804</td>\n",
       "      <td>1.300000e-02</td>\n",
       "      <td>0.101887</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>0.109266</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>15.09</td>\n",
       "      <td>4.917510</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.473709</td>\n",
       "      <td>-7.250000e-03</td>\n",
       "      <td>0.109390</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.119042</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.126886</td>\n",
       "      <td>15.33</td>\n",
       "      <td>4.662735</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.466476</td>\n",
       "      <td>1.700000e-02</td>\n",
       "      <td>0.107464</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.117898</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.134086</td>\n",
       "      <td>16.10</td>\n",
       "      <td>5.193265</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>-8.750000e-03</td>\n",
       "      <td>0.113047</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.133551</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>16.65</td>\n",
       "      <td>4.355169</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>2.250000e-03</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.122192</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.118322</td>\n",
       "      <td>15.61</td>\n",
       "      <td>5.308286</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.491833</td>\n",
       "      <td>8.881784e-18</td>\n",
       "      <td>0.097468</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.122784</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.116258</td>\n",
       "      <td>16.08</td>\n",
       "      <td>4.601478</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>-3.250000e-03</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.105830</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.116722</td>\n",
       "      <td>13.33</td>\n",
       "      <td>5.656951</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>-2.250000e-02</td>\n",
       "      <td>0.101888</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.120067</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.112654</td>\n",
       "      <td>13.13</td>\n",
       "      <td>5.893479</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.438634</td>\n",
       "      <td>-1.500000e-03</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.108162</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.115308</td>\n",
       "      <td>15.15</td>\n",
       "      <td>5.229484</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>3.150000e-02</td>\n",
       "      <td>0.105037</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.121239</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.105124</td>\n",
       "      <td>15.43</td>\n",
       "      <td>5.140535</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.491833</td>\n",
       "      <td>2.825000e-02</td>\n",
       "      <td>0.091764</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.093723</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.109412</td>\n",
       "      <td>11.43</td>\n",
       "      <td>5.217768</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>2.375000e-02</td>\n",
       "      <td>0.099145</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.102621</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.105432</td>\n",
       "      <td>10.09</td>\n",
       "      <td>4.854060</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.217945</td>\n",
       "      <td>2.400000e-02</td>\n",
       "      <td>0.101176</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.103204</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "10  ESFP  ESFP    INTP  INTP         0.778      0.127734       16.52   \n",
       "6   ESTP  ESTP    INFJ  INFJ         0.779      0.130610       17.11   \n",
       "14  ESTP  ESTP    ISFJ  ISFJ         0.781      0.124656       15.65   \n",
       "8   ESFJ  ESFJ    ISTP  ISTP         0.800      0.117473       15.26   \n",
       "4   ESTJ  ESTJ    INFP  INFP         0.800      0.123288       15.09   \n",
       "12  ESTJ  ESTJ    ISFP  ISFP         0.810      0.126886       15.33   \n",
       "2   ESFP  ESFP    INTJ  INTJ         0.811      0.134086       16.10   \n",
       "0   ESFJ  ESFJ    INTP  INTP         0.815      0.121963       16.65   \n",
       "1   ENTP  ENTP    ISFJ  ISFJ         0.820      0.118322       15.61   \n",
       "5   ENFP  ENFP    ISTJ  ISTJ         0.822      0.116258       16.08   \n",
       "9   ENTP  ENTP    INFJ  INFJ         0.824      0.116722       13.33   \n",
       "13  ENFP  ENFP    INTJ  INTJ         0.847      0.112654       13.13   \n",
       "7   ENTJ  ENTJ    ISFP  ISFP         0.852      0.115308       15.15   \n",
       "3   ENFJ  ENFJ    ISTP  ISTP         0.857      0.105124       15.43   \n",
       "15  ENTJ  ENTJ    ISTJ  ISTJ         0.873      0.109412       11.43   \n",
       "11  ENFJ  ENFJ    INFP  INFP         0.878      0.105432       10.09   \n",
       "\n",
       "    std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "10    4.215400           0.55       0.497494     -1.750000e-03   \n",
       "6     3.929109           0.51       0.499900     -3.750000e-02   \n",
       "14    4.879293           0.62       0.485386     -4.500000e-03   \n",
       "8     5.007235           0.63       0.482804      1.300000e-02   \n",
       "4     4.917510           0.66       0.473709     -7.250000e-03   \n",
       "12    4.662735           0.68       0.466476      1.700000e-02   \n",
       "2     5.193265           0.51       0.499900     -8.750000e-03   \n",
       "0     4.355169           0.52       0.499600      2.250000e-03   \n",
       "1     5.308286           0.59       0.491833      8.881784e-18   \n",
       "5     4.601478           0.57       0.495076     -3.250000e-03   \n",
       "9     5.656951           0.76       0.427083     -2.250000e-02   \n",
       "13    5.893479           0.74       0.438634     -1.500000e-03   \n",
       "7     5.229484           0.62       0.485386      3.150000e-02   \n",
       "3     5.140535           0.59       0.491833      2.825000e-02   \n",
       "15    5.217768           0.91       0.286182      2.375000e-02   \n",
       "11    4.854060           0.95       0.217945      2.400000e-02   \n",
       "\n",
       "    std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "10          0.108585              -0.140            0.124097               6  \n",
       "6           0.111664              -0.174            0.134625               8  \n",
       "14          0.117334              -0.133            0.124944               6  \n",
       "8           0.101887              -0.119            0.109266               6  \n",
       "4           0.109390              -0.123            0.119042               8  \n",
       "12          0.107464              -0.110            0.117898               6  \n",
       "2           0.113047              -0.142            0.133551               8  \n",
       "0           0.108921              -0.113            0.122192               8  \n",
       "1           0.097468              -0.118            0.122784               8  \n",
       "5           0.090599              -0.120            0.105830               8  \n",
       "9           0.101888              -0.128            0.120067               6  \n",
       "13          0.083876              -0.101            0.108162               6  \n",
       "7           0.105037              -0.099            0.121239               8  \n",
       "3           0.091764              -0.096            0.093723               8  \n",
       "15          0.099145              -0.087            0.102621               4  \n",
       "11          0.101176              -0.093            0.103204               4  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_fifty = fifty_group.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_fifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_ind, hetero_group = abm_model(condition = heterogenous, \n",
    "        max_ticks = 20, \n",
    "        n_part_exercises = 10, \n",
    "        range_solution = [1, 9], \n",
    "        n_simulations = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alfa</th>\n",
       "      <th>beta</th>\n",
       "      <th>charlie</th>\n",
       "      <th>delta</th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_n_tick</th>\n",
       "      <th>std_n_tick</th>\n",
       "      <th>avg_consensus</th>\n",
       "      <th>std_consensus</th>\n",
       "      <th>avg_weak_synergy</th>\n",
       "      <th>std_weak_synergy</th>\n",
       "      <th>avg_strong_synergy</th>\n",
       "      <th>std_strong_synergy</th>\n",
       "      <th>diversity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.129070</td>\n",
       "      <td>15.30</td>\n",
       "      <td>4.620606</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>-0.01450</td>\n",
       "      <td>0.107888</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.118908</td>\n",
       "      <td>15.96</td>\n",
       "      <td>4.235375</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-0.00425</td>\n",
       "      <td>0.111246</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.130015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.126095</td>\n",
       "      <td>13.44</td>\n",
       "      <td>5.076061</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.375633</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.106055</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.106602</td>\n",
       "      <td>14.89</td>\n",
       "      <td>4.870103</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.098080</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.108715</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.140182</td>\n",
       "      <td>15.18</td>\n",
       "      <td>4.838140</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.470213</td>\n",
       "      <td>-0.00825</td>\n",
       "      <td>0.114894</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.137590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.119210</td>\n",
       "      <td>14.15</td>\n",
       "      <td>5.105634</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>-0.00375</td>\n",
       "      <td>0.103825</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.115633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.137840</td>\n",
       "      <td>15.32</td>\n",
       "      <td>4.837107</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.476970</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.125847</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>0.137637</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.126949</td>\n",
       "      <td>14.52</td>\n",
       "      <td>4.998960</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.448999</td>\n",
       "      <td>0.01175</td>\n",
       "      <td>0.102558</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.115222</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.119042</td>\n",
       "      <td>13.42</td>\n",
       "      <td>5.301283</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.392301</td>\n",
       "      <td>-0.01100</td>\n",
       "      <td>0.101077</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.100374</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.124784</td>\n",
       "      <td>14.56</td>\n",
       "      <td>5.020598</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>-0.00625</td>\n",
       "      <td>0.103705</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.123008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INTP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.098874</td>\n",
       "      <td>12.88</td>\n",
       "      <td>5.099569</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>-0.01700</td>\n",
       "      <td>0.088521</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.100851</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.127574</td>\n",
       "      <td>13.95</td>\n",
       "      <td>5.333620</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.453762</td>\n",
       "      <td>0.00950</td>\n",
       "      <td>0.107516</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.120830</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.110254</td>\n",
       "      <td>13.45</td>\n",
       "      <td>5.167930</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.104551</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>INFP</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.120909</td>\n",
       "      <td>11.77</td>\n",
       "      <td>5.053425</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.336303</td>\n",
       "      <td>-0.00450</td>\n",
       "      <td>0.106029</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.117115</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.108125</td>\n",
       "      <td>13.17</td>\n",
       "      <td>4.783419</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>-0.00275</td>\n",
       "      <td>0.091644</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.101371</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.102034</td>\n",
       "      <td>10.47</td>\n",
       "      <td>5.127290</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.087341</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.106471</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alfa  beta charlie delta  avg_accuracy  std_accuracy  avg_n_tick  \\\n",
       "8   ESFJ  ISTP    ESTP  ENTP         0.779      0.129070       15.30   \n",
       "13  ENTP  INTP    ESFP  ISFP         0.781      0.118908       15.96   \n",
       "6   ENFP  ISFP    ESFP  INFP         0.790      0.126095       13.44   \n",
       "9   ESTJ  ISFP    ISTJ  ESFP         0.806      0.106602       14.89   \n",
       "5   ESTJ  ESTP    ISTP  INTJ         0.807      0.140182       15.18   \n",
       "12  ESFJ  ISFJ    ENFP  INFP         0.817      0.119210       14.15   \n",
       "2   ISTJ  ISTP    ESFP  ENTJ         0.820      0.137840       15.32   \n",
       "1   ISFJ  ESTP    ISFP  ENFJ         0.822      0.126949       14.52   \n",
       "3   INTP  INTJ    INFP  ENTP         0.827      0.119042       13.42   \n",
       "4   ESFJ  ISFJ    ISTJ  INTP         0.827      0.124784       14.56   \n",
       "11  ENFJ  INTP    INFJ  ENTP         0.832      0.098874       12.88   \n",
       "15  ENTJ  INTJ    ESTP  ISTP         0.835      0.127574       13.95   \n",
       "0   ESFJ  ESTJ    ENFP  INFJ         0.838      0.110254       13.45   \n",
       "10  ENFP  INTJ    INFP  ENTJ         0.841      0.120909       11.77   \n",
       "14  ESTJ  ISTJ    ENFJ  INFJ         0.847      0.108125       13.17   \n",
       "7   INFJ  ENFJ    ENTJ  ISFJ         0.867      0.102034       10.47   \n",
       "\n",
       "    std_n_tick  avg_consensus  std_consensus  avg_weak_synergy  \\\n",
       "8     4.620606           0.70       0.458258          -0.01450   \n",
       "13    4.235375           0.64       0.480000          -0.00425   \n",
       "6     5.076061           0.83       0.375633           0.00150   \n",
       "9     4.870103           0.69       0.462493           0.01950   \n",
       "5     4.838140           0.67       0.470213          -0.00825   \n",
       "12    5.105634           0.75       0.433013          -0.00375   \n",
       "2     4.837107           0.65       0.476970           0.01500   \n",
       "1     4.998960           0.72       0.448999           0.01175   \n",
       "3     5.301283           0.81       0.392301          -0.01100   \n",
       "4     5.020598           0.73       0.443959          -0.00625   \n",
       "11    5.099569           0.86       0.346987          -0.01700   \n",
       "15    5.333620           0.71       0.453762           0.00950   \n",
       "0     5.167930           0.80       0.400000           0.00150   \n",
       "10    5.053425           0.87       0.336303          -0.00450   \n",
       "14    4.783419           0.86       0.346987          -0.00275   \n",
       "7     5.127290           0.92       0.271293           0.00300   \n",
       "\n",
       "    std_weak_synergy  avg_strong_synergy  std_strong_synergy diversity_score  \n",
       "8           0.107888              -0.145            0.125200               4  \n",
       "13          0.111246              -0.136            0.130015               6  \n",
       "6           0.106055              -0.139            0.117384               4  \n",
       "9           0.098080              -0.109            0.108715               6  \n",
       "5           0.114894              -0.137            0.137590               5  \n",
       "12          0.103825              -0.127            0.115633               6  \n",
       "2           0.125847              -0.116            0.137637               6  \n",
       "1           0.102558              -0.118            0.115222               6  \n",
       "3           0.101077              -0.125            0.100374               3  \n",
       "4           0.103705              -0.113            0.123008               5  \n",
       "11          0.088521              -0.123            0.100851               6  \n",
       "15          0.107516              -0.120            0.120830               6  \n",
       "0           0.092993              -0.113            0.104551               5  \n",
       "10          0.106029              -0.122            0.117115               6  \n",
       "14          0.091644              -0.118            0.101371               6  \n",
       "7           0.087341              -0.108            0.106471               4  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wsynergy_hetero = hetero_group.sort_values(\"avg_accuracy\", ascending = True)\n",
    "sorted_wsynergy_hetero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8249375000000001, 0.8216875000000001, 0.8210000000000002)\n",
      "(0.043674175364281365, 0.030864054233849456, 0.023229829960634746)\n",
      "(10.788124999999999, 14.872500000000002, 13.901874999999999)\n",
      "(1.9839267210194536, 1.8696039019000787, 1.3748418943191252)\n"
     ]
    }
   ],
   "source": [
    "homogenous_mean_acc = np.mean(homogeous_group_df['avg_accuracy'])\n",
    "fifty_mean_acc = np.mean(fifty_group['avg_accuracy'])\n",
    "hetero_mean_acc = np.mean(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_std_acc = np.std(homogeous_group_df['avg_accuracy'])\n",
    "fifty_std_acc = np.std(fifty_group['avg_accuracy'])\n",
    "hetero_std_acc = np.std(hetero_group['avg_accuracy'])\n",
    "\n",
    "homogenous_mean_tick = np.mean(homogeous_group_df['avg_n_tick'])\n",
    "fifty_mean_tick = np.mean(fifty_group['avg_n_tick'])\n",
    "hetero_mean_tick = np.mean(hetero_group['avg_n_tick'])\n",
    "\n",
    "homogenous_std_tick = np.std(homogeous_group_df['avg_n_tick'])\n",
    "fifty_std_tick = np.std(fifty_group['avg_n_tick'])\n",
    "hetero_std_tick = np.std(hetero_group['avg_n_tick'])\n",
    "\n",
    "print(tuple([homogenous_mean_acc, fifty_mean_acc, hetero_mean_acc]))\n",
    "print(tuple([homogenous_std_acc, fifty_std_acc, hetero_std_acc]))\n",
    "\n",
    "print(tuple([homogenous_mean_tick, fifty_mean_tick, hetero_mean_tick]))\n",
    "print(tuple([homogenous_std_tick, fifty_std_tick, hetero_std_tick]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33078cfce3b48701940fc5b5dd0b6d9b895502e5da868bfe1d8ab2cb40e85d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
